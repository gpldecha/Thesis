\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Motivation}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Contribution}{chapter.1}% 3
\BOOKMARK [2][-]{subsection.1.2.1}{Learning to reason with uncertainty as humans}{section.1.2}% 4
\BOOKMARK [2][-]{subsection.1.2.2}{Reinforcement learning in belief space}{section.1.2}% 5
\BOOKMARK [2][-]{subsection.1.2.3}{Non-parametric Bayesian state space filter}{section.1.2}% 6
\BOOKMARK [1][-]{section.1.3}{Thesis outline}{chapter.1}% 7
\BOOKMARK [0][-]{chapter.2}{Background}{}% 8
\BOOKMARK [1][-]{section.2.1}{Decisions under uncertainty}{chapter.2}% 9
\BOOKMARK [2][-]{subsection.2.1.1}{Decision theory}{section.2.1}% 10
\BOOKMARK [1][-]{section.2.2}{Sequential decision making}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.2.1}{POMDP}{section.2.2}% 12
\BOOKMARK [1][-]{section.2.3}{Literature review}{chapter.2}% 13
\BOOKMARK [2][-]{subsection.2.3.1}{Value Iteration}{section.2.3}% 14
\BOOKMARK [2][-]{subsection.2.3.2}{Policy search}{section.2.3}% 15
\BOOKMARK [2][-]{subsection.2.3.3}{Planning}{section.2.3}% 16
\BOOKMARK [2][-]{subsection.2.3.4}{Heuristics}{section.2.3}% 17
\BOOKMARK [2][-]{subsection.2.3.5}{Summary: literature}{section.2.3}% 18
\BOOKMARK [1][-]{section.2.4}{Approach}{chapter.2}% 19
\BOOKMARK [0][-]{chapter.3}{Learning to reason with uncertainty as humans}{}% 20
\BOOKMARK [1][-]{section.3.1}{Outline}{chapter.3}% 21
\BOOKMARK [1][-]{section.3.2}{Background}{chapter.3}% 22
\BOOKMARK [2][-]{subsection.3.2.1}{Spatial navigation}{section.3.2}% 23
\BOOKMARK [2][-]{subsection.3.2.2}{Human beliefs}{section.3.2}% 24
\BOOKMARK [2][-]{subsection.3.2.3}{Programming by demonstration \046 uncertainty}{section.3.2}% 25
\BOOKMARK [1][-]{section.3.3}{Experiment: table search}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.4}{Formulation}{chapter.3}% 27
\BOOKMARK [1][-]{section.3.5}{Policies}{chapter.3}% 28
\BOOKMARK [2][-]{subsection.3.5.1}{Modelling human search strategies}{section.3.5}% 29
\BOOKMARK [2][-]{subsection.3.5.2}{Coastal Navigation}{section.3.5}% 30
\BOOKMARK [2][-]{subsection.3.5.3}{Control}{section.3.5}% 31
\BOOKMARK [1][-]{section.3.6}{Results and discussion}{chapter.3}% 32
\BOOKMARK [2][-]{subsection.3.6.1}{Search \046 behaviour analysis}{section.3.6}% 33
\BOOKMARK [2][-]{subsection.3.6.2}{GMM \046 Coastal Navigation policy analysis}{section.3.6}% 34
\BOOKMARK [2][-]{subsection.3.6.3}{Distance efficiency \046 Uncertainty}{section.3.6}% 35
\BOOKMARK [1][-]{section.3.7}{Conclusions}{chapter.3}% 36
\BOOKMARK [0][-]{chapter.4}{Peg in hole}{}% 37
\BOOKMARK [1][-]{section.4.1}{Background}{chapter.4}% 38
\BOOKMARK [2][-]{subsection.4.1.1}{Peg-in-hole}{section.4.1}% 39
\BOOKMARK [1][-]{section.4.2}{Experiment}{chapter.4}% 40
\BOOKMARK [1][-]{section.4.3}{Formulation}{chapter.4}% 41
\BOOKMARK [2][-]{subsection.4.3.1}{Belief probability density function}{section.4.3}% 42
\BOOKMARK [2][-]{subsection.4.3.2}{Belief compression}{section.4.3}% 43
\BOOKMARK [1][-]{section.4.4}{Learning Actor and Critic}{chapter.4}% 44
\BOOKMARK [2][-]{subsection.4.4.1}{Actor}{section.4.4}% 45
\BOOKMARK [2][-]{subsection.4.4.2}{Critic}{section.4.4}% 46
\BOOKMARK [2][-]{subsection.4.4.3}{Actor update}{section.4.4}% 47
\BOOKMARK [1][-]{section.4.5}{Control architecture}{chapter.4}% 48
\BOOKMARK [1][-]{section.4.6}{Results}{chapter.4}% 49
\BOOKMARK [2][-]{subsection.4.6.1}{Distance taken to reach the socket's edge \(Qualitative\)}{section.4.6}% 50
\BOOKMARK [2][-]{subsection.4.6.2}{Distance taken to reach the socket's edge \(Quantitative\)}{section.4.6}% 51
\BOOKMARK [2][-]{subsection.4.6.3}{Importance of data}{section.4.6}% 52
\BOOKMARK [2][-]{subsection.4.6.4}{Generalisation}{section.4.6}% 53
\BOOKMARK [2][-]{subsection.4.6.5}{Distance taken to connect the plug to the socket}{section.4.6}% 54
\BOOKMARK [1][-]{section.4.7}{Discussion \046 Conclusion}{chapter.4}% 55
\BOOKMARK [1][-]{section.4.8}{Appendix}{chapter.4}% 56
\BOOKMARK [2][-]{subsection.4.8.1}{EM policy search}{section.4.8}% 57
\BOOKMARK [2][-]{subsection.4.8.2}{Q-EM for GMM derivation}{section.4.8}% 58
\BOOKMARK [2][-]{subsection.4.8.3}{Unbiased estimator}{section.4.8}% 59
\BOOKMARK [0][-]{chapter.5}{Non-parametric Bayesian State Space Estimator}{}% 60
\BOOKMARK [1][-]{section.5.1}{Outline}{chapter.5}% 61
\BOOKMARK [1][-]{section.5.2}{Background}{chapter.5}% 62
\BOOKMARK [2][-]{subsection.5.2.1}{SLAM}{section.5.2}% 63
\BOOKMARK [2][-]{subsection.5.2.2}{Active-SLAM \046 Exploration}{section.5.2}% 64
\BOOKMARK [1][-]{section.5.3}{Bayesian State Space Estimation}{chapter.5}% 65
\BOOKMARK [1][-]{section.5.4}{Measurement Likelihood Memory Filter}{chapter.5}% 66
\BOOKMARK [2][-]{subsection.5.4.1}{MLMF parametrisation}{section.5.4}% 67
\BOOKMARK [2][-]{subsection.5.4.2}{Computation of evidence and marginals}{section.5.4}% 68
\BOOKMARK [2][-]{subsection.5.4.3}{MLMF-SLAM Algorithm}{section.5.4}% 69
\BOOKMARK [2][-]{subsection.5.4.4}{Space \046 time complexity \(MLMF\)}{section.5.4}% 70
\BOOKMARK [2][-]{subsection.5.4.5}{Scalable extension to multiple objects}{section.5.4}% 71
\BOOKMARK [1][-]{section.5.5}{Evaluation}{chapter.5}% 72
\BOOKMARK [2][-]{subsection.5.5.1}{Evaluation of time complexity}{section.5.5}% 73
\BOOKMARK [2][-]{subsection.5.5.2}{Evaluation of independence assumption}{section.5.5}% 74
\BOOKMARK [2][-]{subsection.5.5.3}{Evaluation of memory}{section.5.5}% 75
\BOOKMARK [1][-]{section.5.6}{Conclusion}{chapter.5}% 76
\BOOKMARK [1][-]{section.5.7}{Appendix}{chapter.5}% 77
\BOOKMARK [2][-]{subsection.5.7.1}{Bayesian joint to filter}{section.5.7}% 78
\BOOKMARK [2][-]{subsection.5.7.2}{Bayesian filtering recursion}{section.5.7}% 79
\BOOKMARK [2][-]{subsection.5.7.3}{Derivation of the evidence}{section.5.7}% 80
\BOOKMARK [2][-]{subsection.5.7.4}{Derivation of the marginal}{section.5.7}% 81
\BOOKMARK [0][-]{chapter*.97}{References}{}% 82
