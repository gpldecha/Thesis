\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Bernoulli1954}
\citation{VonNeumann1944}
\citation{ActingUncertainty_1996}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}}
\@writefile{brf}{\backcite{Bernoulli1954}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{VonNeumann1944}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{ActingUncertainty_1996}{{1}{1.1}{section.1.1}}}
\citation{Billard08chapter}
\citation{stankiewicz2006lost}
\citation{Thrun_Burgard_Fox_2005}
\@writefile{brf}{\backcite{Billard08chapter}{{2}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{stankiewicz2006lost}{{2}{1.1}{section.1.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contribution}{2}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Learning to reason with uncertainty as humans}{2}{subsection.1.2.1}}
\citation{Bake_Saxe_Tene_2011}
\@writefile{brf}{\backcite{Thrun_Burgard_Fox_2005}{{3}{1.2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{Bake_Saxe_Tene_2011}{{3}{1.2.1}{subsection.1.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Non-parametric Bayesian state space filter}{3}{subsection.1.2.2}}
\citation{rai2013learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Reinforcement learning in belief space}{4}{subsection.1.2.3}}
\@writefile{brf}{\backcite{rai2013learning}{{4}{1.2.3}{subsection.1.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis outline}{4}{section.1.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Decisions under Uncertainty}{5}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Decision theory}{6}{subsection.2.1.1}}
\citation{Bernoulli1954}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces ad\relax }}{7}{figure.caption.1}}
\@writefile{brf}{\backcite{Bernoulli1954}{{7}{2.1.1}{figure.caption.1}}}
\citation{VonNeumann1944}
\newlabel{eq:exp_utility}{{2.1.1}{8}{Decision theory}{figure.caption.1}{}}
\@writefile{brf}{\backcite{VonNeumann1944}{{8}{2.1.1}{figure.caption.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Beliefs \& desires}{8}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Sequential decision process}{8}{section.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Definition of common variables used.\relax }}{9}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:notation}{{2.1}{9}{Definition of common variables used.\relax }{table.caption.2}{}}
\newlabel{eq:joint_state_actions_util}{{2.1}{10}{Sequential decision process}{equation.2.2.1}{}}
\newlabel{fig:mdp_off}{{2.2(a)}{11}{Subfigure 2 2.2(a)}{subfigure.2.2.1}{}}
\newlabel{sub@fig:mdp_off}{{(a)}{11}{Subfigure 2 2.2(a)\relax }{subfigure.2.2.1}{}}
\newlabel{fig:mdp_on}{{2.2(b)}{11}{Subfigure 2 2.2(b)}{subfigure.2.2.2}{}}
\newlabel{sub@fig:mdp_on}{{(b)}{11}{Subfigure 2 2.2(b)\relax }{subfigure.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Dynamical Bayesian Network of a Markov Decision Process; it encodes the temporal relation between the random variables (circles), utilities (diamond) and decisions (squares). The arrows specify conditional distributions. In \textbf  {(a)} the decision nodes are not considered random variables whilst in \textbf  {(b)} they are. From these two DBN we can read off two conditional distributions, the state transition distribution (in red) and the action distribution (in purple). \relax }}{11}{figure.caption.3}}
\newlabel{fig:mdp}{{2.2}{11}{Dynamical Bayesian Network of a Markov Decision Process; it encodes the temporal relation between the random variables (circles), utilities (diamond) and decisions (squares). The arrows specify conditional distributions. In \textbf {(a)} the decision nodes are not considered random variables whilst in \textbf {(b)} they are. From these two DBN we can read off two conditional distributions, the state transition distribution (in red) and the action distribution (in purple). \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {off-policy}}}{11}{figure.caption.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {on-policy}}}{11}{figure.caption.3}}
\newlabel{eq:joint_state_actions}{{2.2}{11}{Sequential decision process}{equation.2.2.2}{}}
\newlabel{eq:temporal_expected_utility}{{2.4}{11}{Sequential decision process}{equation.2.2.4}{}}
\newlabel{eq:max_util}{{2.2}{11}{Sequential decision process}{equation.2.2.4}{}}
\newlabel{eq:expansion}{{2.5}{12}{Sequential decision process}{equation.2.2.5}{}}
\newlabel{eq:bellman}{{2.6}{12}{Sequential decision process}{equation.2.2.6}{}}
\newlabel{eq:on_policy_bellman}{{2.7}{12}{Sequential decision process}{equation.2.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}POMDP}{13}{subsection.2.2.1}}
\newlabel{eq:sensor}{{2.8}{13}{POMDP}{equation.2.2.8}{}}
\newlabel{eq:likelihood}{{2.9}{14}{POMDP}{equation.2.2.9}{}}
\newlabel{fig:motion_update}{{2.3(a)}{14}{Subfigure 2 2.3(a)}{subfigure.2.3.1}{}}
\newlabel{sub@fig:motion_update}{{(a)}{14}{Subfigure 2 2.3(a)\relax }{subfigure.2.3.1}{}}
\newlabel{fig:measurement}{{2.3(b)}{14}{Subfigure 2 2.3(b)}{subfigure.2.3.2}{}}
\newlabel{sub@fig:measurement}{{(b)}{14}{Subfigure 2 2.3(b)\relax }{subfigure.2.3.2}{}}
\newlabel{fig:likelihood}{{2.3(c)}{14}{Subfigure 2 2.3(c)}{subfigure.2.3.3}{}}
\newlabel{sub@fig:likelihood}{{(c)}{14}{Subfigure 2 2.3(c)\relax }{subfigure.2.3.3}{}}
\newlabel{fig:measurement_update}{{2.3(d)}{14}{Subfigure 2 2.3(d)}{subfigure.2.3.4}{}}
\newlabel{sub@fig:measurement_update}{{(d)}{14}{Subfigure 2 2.3(d)\relax }{subfigure.2.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \textbf  {(a)} An agent is located to the south west of a brick wall, it is equipped with a range sensor. The agent takes a forward action, but skids which results in a high increase of the uncertainty.\textbf  {(b)} The agent takes a measurement, $y_0$, of this distance to the wall; because his sensor is noisy his estimate is off. \textbf  {(c)} The agent uses with his measurement model to evaluate the plausibility of all locations in the world which would result in a similar measurement; illustrated by the likelihood function $p(y_0|x_0)$. \textbf  {(d)} The likelihood is integrated into the probability density function; $p(x_0|y_0) \propto p(y_0|x)p(x_0)$.\relax }}{14}{figure.caption.4}}
\newlabel{fig:belief_update_example}{{2.3}{14}{\textbf {(a)} An agent is located to the south west of a brick wall, it is equipped with a range sensor. The agent takes a forward action, but skids which results in a high increase of the uncertainty.\textbf {(b)} The agent takes a measurement, $y_0$, of this distance to the wall; because his sensor is noisy his estimate is off. \textbf {(c)} The agent uses with his measurement model to evaluate the plausibility of all locations in the world which would result in a similar measurement; illustrated by the likelihood function $p(y_0|x_0)$. \textbf {(d)} The likelihood is integrated into the probability density function; $p(x_0|y_0) \propto p(y_0|x)p(x_0)$.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{14}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{14}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{14}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{14}{figure.caption.4}}
\newlabel{eq:motion_update}{{2.10}{15}{POMDP}{equation.2.2.10}{}}
\newlabel{eq:measurement_update}{{2.11}{15}{POMDP}{equation.2.2.11}{}}
\newlabel{fig:sub_pomdp}{{2.4(a)}{15}{Subfigure 2 2.4(a)}{subfigure.2.4.1}{}}
\newlabel{sub@fig:sub_pomdp}{{(a)}{15}{Subfigure 2 2.4(a)\relax }{subfigure.2.4.1}{}}
\newlabel{fig:sub_bmdp}{{2.4(b)}{15}{Subfigure 2 2.4(b)}{subfigure.2.4.2}{}}
\newlabel{sub@fig:sub_bmdp}{{(b)}{15}{Subfigure 2 2.4(b)\relax }{subfigure.2.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces \relax }}{15}{figure.caption.5}}
\newlabel{fig:pomdp}{{2.4}{15}{\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {off-policy}}}{15}{figure.caption.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {on-policy}}}{15}{figure.caption.5}}
\citation{Sol_POMDP_Policy_space_1998}
\newlabel{eq:optimal_value_f}{{2.12}{16}{POMDP}{equation.2.2.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces ad\relax }}{16}{figure.caption.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}State of the art}{16}{section.2.3}}
\@writefile{brf}{\backcite{Sol_POMDP_Policy_space_1998}{{16}{2.3}{section.2.3}}}
\@writefile{toc}{\contentsline {subsubsection}{Tree search}{16}{section*.7}}
\citation{Quadrator_2008}
\citation{BelRoadMap_2009}
\citation{Erez10ascalable}
\citation{mc_update_ppomdps}
\citation{Platt-RSS-10}
\citation{Bayesian_explor_exploit_2009}
\citation{Spaan05icra}
\citation{Thrun_2005}
\citation{Rand_belief_space_replanning}
\citation{Ross08onlineplanning}
\citation{Macro_uncertainty_2011}
\@writefile{toc}{\contentsline {subsubsection}{Planning}{17}{section*.8}}
\@writefile{brf}{\backcite{Quadrator_2008}{{17}{2.3}{section*.8}}}
\@writefile{brf}{\backcite{BelRoadMap_2009}{{17}{2.3}{section*.8}}}
\@writefile{toc}{\contentsline {subsubsection}{Optimal control}{17}{section*.9}}
\@writefile{brf}{\backcite{Erez10ascalable}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{mc_update_ppomdps}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Platt-RSS-10}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Bayesian_explor_exploit_2009}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Spaan05icra}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Thrun_2005}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Rand_belief_space_replanning}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Ross08onlineplanning}{{17}{2.3}{section*.9}}}
\@writefile{brf}{\backcite{Macro_uncertainty_2011}{{17}{2.3}{section*.9}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Summary}{17}{section.2.4}}
\bibstyle{plainnat}
\bibdata{bib/all_citations.bib,bib/pomdp.bib,bib/ProspectTheory.bib}
\bibcite{Bake_Saxe_Tene_2011}{{1}{2011}{{Bake et~al.}}{{Bake, Tenenbaum, and Saxe}}}
\bibcite{Bernoulli1954}{{2}{1954}{{Bernoulli}}{{}}}
\bibcite{Billard08chapter}{{3}{2008}{{Billard et~al.}}{{Billard, Calinon, Dillmann, and Schaal}}}
\bibcite{mc_update_ppomdps}{{4}{2011}{{Brooks and Williams}}{{}}}
\bibcite{ActingUncertainty_1996}{{5}{1996}{{Cassandra et~al.}}{{Cassandra, Kaelbling, and Kurien}}}
\bibcite{Erez10ascalable}{{6}{2010}{{Erez and Smart}}{{}}}
\bibcite{Sol_POMDP_Policy_space_1998}{{7}{1998}{{Hansen}}{{}}}
\bibcite{Rand_belief_space_replanning}{{8}{2010}{{Hauser}}{{}}}
\bibcite{Quadrator_2008}{{9}{2008}{{He et~al.}}{{He, Prentice, and Roy}}}
\bibcite{Macro_uncertainty_2011}{{10}{2011}{{He et~al.}}{{He, Brunskill, and Roy}}}
\@writefile{toc}{\contentsline {chapter}{References}{19}{chapter*.10}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{Kahneman79prospecttheory}{{11}{1979}{{Kahneman and Tversky}}{{}}}
\bibcite{Bayesian_explor_exploit_2009}{{12}{2009}{{Martinez-Cantin et~al.}}{{Martinez-Cantin, de~Freitas, Brochu, Castellanos, and Doucet}}}
\bibcite{Platt-RSS-10}{{13}{2010}{{Platt et~al.}}{{Platt, Tedrake, Kaelbling, and Lozano-Perez}}}
\bibcite{BelRoadMap_2009}{{14}{2009}{{Prentice and Roy}}{{}}}
\bibcite{rai2013learning}{{15}{2013}{{Rai et~al.}}{{Rai, De~Chambrier, and Billard}}}
\bibcite{Ross08onlineplanning}{{16}{2008}{{Ross et~al.}}{{Ross, Pineau, Paquet, and Chaib-draa}}}
\bibcite{Spaan05icra}{{17}{2005}{{Spaan and Vlassis}}{{}}}
\bibcite{stankiewicz2006lost}{{18}{2006}{{Stankiewicz et~al.}}{{Stankiewicz, Legge, Mansfield, and Schlicht}}}
\bibcite{Thrun_2005}{{19}{2005{a}}{{Thrun et~al.}}{{Thrun, Burgard, and Fox}}}
\bibcite{Thrun_Burgard_Fox_2005}{{20}{2005{b}}{{Thrun et~al.}}{{Thrun, Burgard, and Fox}}}
\bibcite{VonNeumann1944}{{21}{1990}{{Von~Neumann and Morgenstern}}{{}}}
