\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{decision_un_2013}
\citation{Bernoulli1954}
\citation{VonNeumann1944}
\citation{ActingUncertainty_1996}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}}
\@writefile{brf}{\backcite{decision_un_2013}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{Bernoulli1954}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{VonNeumann1944}{{1}{1.1}{section.1.1}}}
\citation{Billard08chapter}
\citation{stankiewicz2006lost}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Examples of the decision making under uncertainty in both robotics and everyday life situations. Images taken from the public domain.\relax }}{2}{figure.caption.1}}
\@writefile{brf}{\backcite{ActingUncertainty_1996}{{2}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{Billard08chapter}{{2}{1.1}{figure.caption.1}}}
\@writefile{brf}{\backcite{stankiewicz2006lost}{{2}{1.1}{figure.caption.1}}}
\citation{Bake_Saxe_Tene_2011}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contribution}{3}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Learning to reason with uncertainty as humans}{3}{subsection.1.2.1}}
\@writefile{brf}{\backcite{Bake_Saxe_Tene_2011}{{3}{1.2.1}{subsection.1.2.1}}}
\citation{rai2013learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Non-parametric Bayesian state space filter}{4}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Reinforcement learning in belief space}{4}{subsection.1.2.3}}
\@writefile{brf}{\backcite{rai2013learning}{{4}{1.2.3}{subsection.1.2.3}}}
\citation{Chambrier2014}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis outline}{5}{section.1.3}}
\@writefile{brf}{\backcite{Chambrier2014}{{5}{1.3}{section.1.3}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Decisions under uncertainty}{7}{section.2.1}}
\newlabel{sec:deci_un}{{2.1}{7}{Decisions under uncertainty}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Decision theory}{8}{subsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Relation between beliefs, desires and actions and are all considered to be rational.\relax }}{9}{figure.caption.2}}
\citation{Bernoulli1954}
\citation{VonNeumann1944}
\@writefile{brf}{\backcite{Bernoulli1954}{{10}{2.1.1}{figure.caption.2}}}
\newlabel{eq:exp_utility}{{2.1.1}{10}{Decision theory}{figure.caption.2}{}}
\@writefile{brf}{\backcite{VonNeumann1944}{{10}{2.1.1}{figure.caption.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Sequential decision making}{11}{section.2.2}}
\newlabel{sec:sqp}{{2.2}{11}{Sequential decision making}{section.2.2}{}}
\newlabel{eq:joint_state_actions_util}{{2.1}{11}{Sequential decision making}{equation.2.2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Definition of common variables used.\relax }}{12}{table.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:notation}{{2.1}{12}{Definition of common variables used.\relax }{table.caption.3}{}}
\newlabel{fig:mdp_off}{{2.2(a)}{13}{Subfigure 2 2.2(a)}{subfigure.2.2.1}{}}
\newlabel{sub@fig:mdp_off}{{(a)}{13}{Subfigure 2 2.2(a)\relax }{subfigure.2.2.1}{}}
\newlabel{fig:mdp_on}{{2.2(b)}{13}{Subfigure 2 2.2(b)}{subfigure.2.2.2}{}}
\newlabel{sub@fig:mdp_on}{{(b)}{13}{Subfigure 2 2.2(b)\relax }{subfigure.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Dynamical Bayesian Network of a Markov Decision Process; it encodes the temporal relation between the random variables (circles), utilities (diamond) and decisions (squares). The arrows specify conditional distributions. In \textbf  {(a)} the decision nodes are not considered random variables whilst in \textbf  {(b)} they are. From these two DBN we can read off two conditional distributions, the state transition distribution (in red) and the action distribution (in purple). \relax }}{13}{figure.caption.4}}
\newlabel{fig:mdp}{{2.2}{13}{Dynamical Bayesian Network of a Markov Decision Process; it encodes the temporal relation between the random variables (circles), utilities (diamond) and decisions (squares). The arrows specify conditional distributions. In \textbf {(a)} the decision nodes are not considered random variables whilst in \textbf {(b)} they are. From these two DBN we can read off two conditional distributions, the state transition distribution (in red) and the action distribution (in purple). \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {off-policy}}}{13}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {on-policy}}}{13}{figure.caption.4}}
\newlabel{eq:joint_state_actions}{{2.2}{13}{Sequential decision making}{equation.2.2.2}{}}
\newlabel{eq:temporal_expected_utility}{{2.4}{13}{Sequential decision making}{equation.2.2.4}{}}
\newlabel{eq:expansion}{{2.5}{14}{Sequential decision making}{equation.2.2.5}{}}
\newlabel{eq:bellman}{{2.6}{14}{Sequential decision making}{equation.2.2.6}{}}
\newlabel{eq:on_policy_bellman}{{2.7}{14}{Sequential decision making}{equation.2.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}POMDP}{15}{subsection.2.2.1}}
\newlabel{eq:sensor}{{2.8}{15}{POMDP}{equation.2.2.8}{}}
\newlabel{eq:likelihood}{{2.9}{16}{POMDP}{equation.2.2.9}{}}
\newlabel{fig:motion_update}{{2.3(a)}{17}{Subfigure 2 2.3(a)}{subfigure.2.3.1}{}}
\newlabel{sub@fig:motion_update}{{(a)}{17}{Subfigure 2 2.3(a)\relax }{subfigure.2.3.1}{}}
\newlabel{fig:measurement}{{2.3(b)}{17}{Subfigure 2 2.3(b)}{subfigure.2.3.2}{}}
\newlabel{sub@fig:measurement}{{(b)}{17}{Subfigure 2 2.3(b)\relax }{subfigure.2.3.2}{}}
\newlabel{fig:likelihood}{{2.3(c)}{17}{Subfigure 2 2.3(c)}{subfigure.2.3.3}{}}
\newlabel{sub@fig:likelihood}{{(c)}{17}{Subfigure 2 2.3(c)\relax }{subfigure.2.3.3}{}}
\newlabel{fig:measurement_update}{{2.3(d)}{17}{Subfigure 2 2.3(d)}{subfigure.2.3.4}{}}
\newlabel{sub@fig:measurement_update}{{(d)}{17}{Subfigure 2 2.3(d)\relax }{subfigure.2.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \textbf  {(a)} An agent is located to the south west of a brick wall, it is equipped with a range sensor. The agent takes a forward action, but skids which results in a high increase of the uncertainty.\textbf  {(b)} The agent takes a measurement, $y_0$, of this distance to the wall; because his sensor is noisy his estimate is off. \textbf  {(c)} The agent uses with his measurement model to evaluate the plausibility of all locations in the world which would result in a similar measurement; illustrated by the likelihood function $p(y_0|x_0)$. \textbf  {(d)} The likelihood is integrated into the probability density function; $p(x_0|y_0) \propto p(y_0|x)p(x_0)$.\relax }}{17}{figure.caption.5}}
\newlabel{fig:belief_update_example}{{2.3}{17}{\textbf {(a)} An agent is located to the south west of a brick wall, it is equipped with a range sensor. The agent takes a forward action, but skids which results in a high increase of the uncertainty.\textbf {(b)} The agent takes a measurement, $y_0$, of this distance to the wall; because his sensor is noisy his estimate is off. \textbf {(c)} The agent uses with his measurement model to evaluate the plausibility of all locations in the world which would result in a similar measurement; illustrated by the likelihood function $p(y_0|x_0)$. \textbf {(d)} The likelihood is integrated into the probability density function; $p(x_0|y_0) \propto p(y_0|x)p(x_0)$.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{17}{figure.caption.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{17}{figure.caption.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{17}{figure.caption.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{17}{figure.caption.5}}
\newlabel{eq:motion_update}{{2.10}{18}{POMDP}{equation.2.2.10}{}}
\newlabel{eq:measurement_update}{{2.11}{18}{POMDP}{equation.2.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Bayesian state space filter.\relax }}{18}{figure.caption.6}}
\newlabel{fig:sub_pomdp}{{2.5(a)}{18}{Subfigure 2 2.5(a)}{subfigure.2.5.1}{}}
\newlabel{sub@fig:sub_pomdp}{{(a)}{18}{Subfigure 2 2.5(a)\relax }{subfigure.2.5.1}{}}
\newlabel{fig:sub_bmdp}{{2.5(b)}{18}{Subfigure 2 2.5(b)}{subfigure.2.5.2}{}}
\newlabel{sub@fig:sub_bmdp}{{(b)}{18}{Subfigure 2 2.5(b)\relax }{subfigure.2.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces \textbf  {(a)} POMDP graphical model. The state space, $X$, is hidden, but is still partially observable through a measurement, $Y$. \textbf  {(b)} belief-MDP, the POMDP is cast into a belief Markov Decision Process. The state space is a probability distribution, $b(x_t) = p(x_t)$, (known as a belief state) and is no longer considered a latent state. The original state transition function $p(x_{t+1}|x_t,a_t)$ is replaced by a belief state transition, $p(b_{t+1}|b_t,a_t)$. The reward is now a function of the belief.\relax }}{18}{figure.caption.7}}
\newlabel{fig:pomdp}{{2.5}{18}{\textbf {(a)} POMDP graphical model. The state space, $X$, is hidden, but is still partially observable through a measurement, $Y$. \textbf {(b)} belief-MDP, the POMDP is cast into a belief Markov Decision Process. The state space is a probability distribution, $b(x_t) = p(x_t)$, (known as a belief state) and is no longer considered a latent state. The original state transition function $p(x_{t+1}|x_t,a_t)$ is replaced by a belief state transition, $p(b_{t+1}|b_t,a_t)$. The reward is now a function of the belief.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{18}{figure.caption.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{18}{figure.caption.7}}
\citation{Sondik_1973}
\newlabel{eq:belief_bellman}{{2.15}{19}{POMDP}{equation.2.2.15}{}}
\newlabel{eq:belief_state_transformation}{{2.16}{19}{POMDP}{equation.2.2.16}{}}
\newlabel{eq:max_component}{{2.17}{19}{POMDP}{equation.2.2.17}{}}
\newlabel{eq:final_belief_bellman}{{2.18}{19}{POMDP}{equation.2.2.18}{}}
\@writefile{brf}{\backcite{Sondik_1973}{{19}{2.2.1}{equation.2.2.18}}}
\citation{Thrun_2005}
\citation{Kaelbling_1998}
\citation{POMDP_approach_2010}
\@writefile{brf}{\backcite{Thrun_2005}{{20}{2.2.1}{equation.2.2.18}}}
\@writefile{brf}{\backcite{Kaelbling_1998}{{20}{2.2.1}{equation.2.2.18}}}
\@writefile{brf}{\backcite{POMDP_approach_2010}{{20}{2.2.1}{equation.2.2.18}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Literature review}{20}{section.2.3}}
\newlabel{sec:lit_rev}{{2.3}{20}{Literature review}{section.2.3}{}}
\@input{./ch2-Background/scientific-interactions.aux}
\citation{Thrun_2005}
\citation{PBVI}
\citation{HSV}
\citation{HSVI2}
\citation{FSVI}
\citation{SARSOP}
\citation{POMDP_approach_2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Point-based Value Iteration}{22}{subsection.2.3.1}}
\@writefile{brf}{\backcite{Thrun_2005}{{22}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{PBVI}{{22}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{HSV}{{22}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{HSVI2}{{22}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{FSVI}{{22}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{SARSOP}{{22}{2.3.1}{subsection.2.3.1}}}
\citation{Spaan05icra}
\citation{PBVI_C_2006}
\citation{solving_continous_pomdps_2013}
\citation{Ross08onlineplanning}
\@writefile{brf}{\backcite{POMDP_approach_2010}{{23}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{Spaan05icra}{{23}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{PBVI_C_2006}{{23}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{solving_continous_pomdps_2013}{{23}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{Ross08onlineplanning}{{23}{2.3.1}{subsection.2.3.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Parametric Value Iteration}{23}{subsection.2.3.2}}
\citation{MC-POMDP}
\citation{Tree_batch_2005}
\citation{mc_update_ppomdps}
\citation{Roy99coastalnavigation}
\citation{belief_compression_2005}
\citation{EPCA_2003}
\citation{bs_compression_2010}
\@writefile{brf}{\backcite{MC-POMDP}{{24}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{Tree_batch_2005}{{24}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{mc_update_ppomdps}{{24}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{Roy99coastalnavigation}{{24}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{belief_compression_2005}{{24}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{EPCA_2003}{{24}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{bs_compression_2010}{{24}{2.3.2}{subsection.2.3.2}}}
\citation{neura_fqi_2005}
\citation{DRQ_AAAI_2015}
\citation{mnih-dqn-2015}
\@writefile{brf}{\backcite{neura_fqi_2005}{{25}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{DRQ_AAAI_2015}{{25}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{mnih-dqn-2015}{{25}{2.3.2}{subsection.2.3.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Policy search}{25}{subsection.2.3.3}}
\citation{reinforce_1992}
\citation{gpomdp_2000}
\citation{sis_pomdp_2002}
\citation{Pegasus_2000}
\citation{heli_2004}
\citation{eNAC_2003}
\citation{NAC_2008}
\citation{PoWER_2009}
\citation{archery_2010}
\citation{pancake_2010}
\citation{Wang2016}
\@writefile{brf}{\backcite{reinforce_1992}{{26}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{gpomdp_2000}{{26}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{sis_pomdp_2002}{{26}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{Pegasus_2000}{{26}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{heli_2004}{{26}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{eNAC_2003}{{26}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{NAC_2008}{{26}{2.3.3}{subsection.2.3.3}}}
\citation{p_search_surv_2011}
\citation{RL_robots_surv_2013}
\citation{dmp_seq_2012}
\citation{dmp_iros_2011}
\citation{BelRoadMap_2009}
\citation{Quadrator_2008}
\citation{FIRM_2011}
\citation{rob_online_bs_icra_2014}
\citation{bsp_rss_2010a}
\citation{van_den_Berg_2012}
\citation{sigma_hull_iros_2013}
\@writefile{brf}{\backcite{PoWER_2009}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{archery_2010}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{pancake_2010}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{Wang2016}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{p_search_surv_2011}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{RL_robots_surv_2013}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{dmp_seq_2012}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{dmp_iros_2011}{{27}{2.3.3}{subsection.2.3.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Belief space planning}{27}{subsection.2.3.4}}
\@writefile{brf}{\backcite{BelRoadMap_2009}{{27}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{Quadrator_2008}{{27}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{FIRM_2011}{{27}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{rob_online_bs_icra_2014}{{27}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{bsp_rss_2010a}{{27}{2.3.4}{subsection.2.3.4}}}
\citation{Erez10ascalable}
\citation{Martinez-Cantin2009}
\citation{non_gauss_bel_plan_2012}
\citation{next_best_touch}
\citation{CostalNavigation1999}
\citation{dense_entropy_icra_2014}
\citation{Uncer_reduction_heuristic_2015}
\citation{u_aware_grasp_ICRA_2015}
\citation{Li_2015}
\citation{un_water_inspection_icra_2012}
\citation{Bayesian_explor_exploit_2009}
\citation{Macro_uncertainty_2011}
\@writefile{brf}{\backcite{van_den_Berg_2012}{{28}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{sigma_hull_iros_2013}{{28}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{Erez10ascalable}{{28}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{Martinez-Cantin2009}{{28}{2.3.4}{subsection.2.3.4}}}
\@writefile{brf}{\backcite{non_gauss_bel_plan_2012}{{28}{2.3.4}{subsection.2.3.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Heuristics}{28}{subsection.2.3.5}}
\@writefile{brf}{\backcite{next_best_touch}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{CostalNavigation1999}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{dense_entropy_icra_2014}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{Uncer_reduction_heuristic_2015}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{u_aware_grasp_ICRA_2015}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{Li_2015}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{un_water_inspection_icra_2012}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{Bayesian_explor_exploit_2009}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{brf}{\backcite{Macro_uncertainty_2011}{{28}{2.3.5}{subsection.2.3.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Summary}{29}{section.2.4}}
\newlabel{sec:back_summ}{{2.4}{29}{Summary}{section.2.4}{}}
\bibstyle{plainnat}
\bibdata{bib/RL.bib,bib/pomdp.bib,bib/cpomdp.bib,bib/citations.bib,bib/DT.bib,bib/ToM.bib,bib/spatial_navigation.bib,bib/ProspectTheory.bib}
\bibcite{FIRM_2011}{{1}{2011}{{a.~Agha-mohammadi et~al.}}{{a.~Agha-mohammadi, Chakravorty, and Amato}}}
\bibcite{rob_online_bs_icra_2014}{{2}{2014}{{a.~Agha-mohammadi et~al.}}{{a.~Agha-mohammadi, Agarwal, Mahadevan, Chakravorty, Tomkins, Denny, and Amato}}}
\bibcite{sis_pomdp_2002}{{3}{2002}{{Aberdeen and Baxter}}{{}}}
\bibcite{Bake_Saxe_Tene_2011}{{4}{2011}{{Bake et~al.}}{{Bake, Tenenbaum, and Saxe}}}
\bibcite{gpomdp_2000}{{5}{2000}{{Baxter and Bartlett}}{{}}}
\bibcite{Bernoulli1954}{{6}{1954}{{Bernoulli}}{{}}}
\bibcite{Billard08chapter}{{7}{2008}{{Billard et~al.}}{{Billard, Calinon, Dillmann, and Schaal}}}
\bibcite{solving_continous_pomdps_2013}{{8}{2013}{{Brechtel et~al.}}{{Brechtel, Gindele, and Dillmann}}}
\bibcite{mc_update_ppomdps}{{9}{2011}{{Brooks and Williams}}{{}}}
\@writefile{toc}{\contentsline {chapter}{References}{31}{chapter*.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{ActingUncertainty_1996}{{10}{1996}{{Cassandra et~al.}}{{Cassandra, Kaelbling, and Kurien}}}
\bibcite{u_aware_grasp_ICRA_2015}{{11}{2015}{{Chen and von Wichert}}{{}}}
\bibcite{Chambrier2014}{{12}{2014}{{de~Chambrier and Billard}}{{}}}
\bibcite{p_search_surv_2011}{{13}{2011}{{Deisenroth et~al.}}{{Deisenroth, Neumann, and Peters}}}
\bibcite{POMDP_approach_2010}{{14}{2010}{{Du et~al.}}{{Du, Hsu, Kurniawati, Lee, Ong, and Png}}}
\bibcite{Erez10ascalable}{{15}{2010}{{Erez and Smart}}{{}}}
\bibcite{Tree_batch_2005}{{16}{2005}{{Ernst et~al.}}{{Ernst, Geurts, and Wehenkel}}}
\bibcite{DRQ_AAAI_2015}{{17}{2015}{{Hausknecht and Stone}}{{}}}
\bibcite{Quadrator_2008}{{18}{2008}{{He et~al.}}{{He, Prentice, and Roy}}}
\bibcite{Macro_uncertainty_2011}{{19}{2011}{{He et~al.}}{{He, Brunskill, and Roy}}}
\bibcite{next_best_touch}{{20}{2013}{{Hebert et~al.}}{{Hebert, Howard, Hudson, Ma, and Burdick}}}
\bibcite{un_water_inspection_icra_2012}{{21}{2012}{{Hollinger et~al.}}{{Hollinger, Englot, Hover, Mitra, and Sukhatme}}}
\bibcite{Kaelbling_1998}{{22}{1998}{{Kaelbling et~al.}}{{Kaelbling, Littman, and Cassandra}}}
\bibcite{heli_2004}{{23}{2004}{{Kim et~al.}}{{Kim, Jordan, Sastry, and Ng}}}
\bibcite{PoWER_2009}{{24}{2009}{{Kober and Peters}}{{}}}
\bibcite{RL_robots_surv_2013}{{25}{2013}{{Kober et~al.}}{{Kober, Bagnell, and Peters}}}
\bibcite{pancake_2010}{{26}{2010{a}}{{Kormushev et~al.}}{{Kormushev, Calinon, and Caldwell}}}
\bibcite{archery_2010}{{27}{2010{b}}{{Kormushev et~al.}}{{Kormushev, Calinon, Saegusa, and Metta}}}
\bibcite{SARSOP}{{28}{2008}{{Kurniawati et~al.}}{{Kurniawati, Hsu, and Lee}}}
\bibcite{sigma_hull_iros_2013}{{29}{2013}{{Lee et~al.}}{{Lee, Duan, Patil, Schulman, McCarthy, van~den Berg, Goldberg, and Abbeel}}}
\bibcite{Li_2015}{{30}{2016}{{Li et~al.}}{{Li, Hang, Kragic, and Billard}}}
\bibcite{bs_compression_2010}{{31}{2010}{{Li et~al.}}{{Li, Cheung, and Liu}}}
\bibcite{Bayesian_explor_exploit_2009}{{32}{2009{a}}{{Martinez-Cantin et~al.}}{{Martinez-Cantin, de~Freitas, Brochu, Castellanos, and Doucet}}}
\bibcite{Martinez-Cantin2009}{{33}{2009{b}}{{Martinez-Cantin et~al.}}{{Martinez-Cantin, Freitas, Brochu, Castellanos, and Doucet}}}
\bibcite{mnih-dqn-2015}{{34}{2015}{{Mnih et~al.}}{{Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare, Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik, Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis}}}
\bibcite{Pegasus_2000}{{35}{2000}{{Ng and Jordan}}{{}}}
\bibcite{NAC_2008}{{36}{2008}{{Peters and Schaal}}{{}}}
\bibcite{PBVI}{{37}{2003}{{Pineau et~al.}}{{Pineau, Gordon, and Thrun}}}
\bibcite{non_gauss_bel_plan_2012}{{38}{2012}{{Platt et~al.}}{{Platt, Kaelbling, Lozano-Perez, and Tedrake}}}
\bibcite{bsp_rss_2010a}{{39}{2010}{{Platt et~al.}}{{Platt, Tedrake, Kaelbling, and Lozano-P\'{e}rez}}}
\bibcite{PBVI_C_2006}{{40}{2006}{{Porta et~al.}}{{Porta, Vlassis, Spaan, and Poupart}}}
\bibcite{BelRoadMap_2009}{{41}{2009}{{Prentice and Roy}}{{}}}
\bibcite{decision_un_2013}{{42}{2013}{{Preuschoff et~al.}}{{Preuschoff, Mohr, and Hsu}}}
\bibcite{rai2013learning}{{43}{2013}{{Rai et~al.}}{{Rai, De~Chambrier, and Billard}}}
\bibcite{Sondik_1973}{{44}{1973}{{Richard D.~Smallwood}}{{}}}
\bibcite{neura_fqi_2005}{{45}{2005}{{Riedmiller}}{{}}}
\bibcite{Ross08onlineplanning}{{46}{2008}{{Ross et~al.}}{{Ross, Pineau, Paquet, and Chaib-draa}}}
\bibcite{CostalNavigation1999}{{47}{1999}{{Roy et~al.}}{{Roy, Burgard, Fox, and Thrun}}}
\bibcite{belief_compression_2005}{{48}{2005}{{Roy}}{{}}}
\bibcite{EPCA_2003}{{49}{2003}{{Roy and Gordon}}{{}}}
\bibcite{Roy99coastalnavigation}{{50}{1999}{{Roy and Thrun}}{{}}}
\bibcite{HSV}{{51}{2004}{{Smith and Simmons}}{{}}}
\bibcite{HSVI2}{{52}{2012}{{Smith and Simmons}}{{}}}
\bibcite{Spaan05icra}{{53}{2005}{{Spaan and Vlassis}}{{}}}
\bibcite{stankiewicz2006lost}{{54}{2006}{{Stankiewicz et~al.}}{{Stankiewicz, Legge, Mansfield, and Schlicht}}}
\bibcite{dmp_iros_2011}{{55}{2011}{{Stulp et~al.}}{{Stulp, Theodorou, Kalakrishnan, Pastor, Righetti, and Schaal}}}
\bibcite{dmp_seq_2012}{{56}{2012}{{Stulp et~al.}}{{Stulp, Theodorou, and Schaal}}}
\bibcite{MC-POMDP}{{57}{2000}{{Thrun}}{{}}}
\bibcite{Thrun_2005}{{58}{2005}{{Thrun et~al.}}{{Thrun, Burgard, and Fox}}}
\bibcite{dense_entropy_icra_2014}{{59}{2014}{{Vallve and Andrade{-}Cetto}}{{}}}
\bibcite{van_den_Berg_2012}{{60}{2012}{{van~den Berg et~al.}}{{van~den Berg, Patil, and Alterovitz}}}
\bibcite{FSVI}{{61}{2007}{{Veloso}}{{}}}
\bibcite{eNAC_2003}{{62}{2003}{{Vijayakumar et~al.}}{{Vijayakumar, Shibata, and Schaal}}}
\bibcite{VonNeumann1944}{{63}{1990}{{Von~Neumann and Morgenstern}}{{}}}
\bibcite{Wang2016}{{64}{2016}{{Wang et~al.}}{{Wang, Uchibe, and Doya}}}
\bibcite{reinforce_1992}{{65}{1992}{{Williams}}{{}}}
\bibcite{Uncer_reduction_heuristic_2015}{{66}{2015}{{Zhang et~al.}}{{Zhang, Rekleitis, and Dudek}}}
