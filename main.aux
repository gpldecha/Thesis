\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Bernoulli1954}
\citation{VonNeumann1944}
\citation{ActingUncertainty_1996}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}}
\@writefile{brf}{\backcite{Bernoulli1954}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{VonNeumann1944}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{ActingUncertainty_1996}{{1}{1.1}{section.1.1}}}
\citation{Billard08chapter}
\citation{stankiewicz2006lost}
\citation{Thrun_Burgard_Fox_2005}
\@writefile{brf}{\backcite{Billard08chapter}{{2}{1.1}{section.1.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contribution}{2}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Learning to reason with uncertainty as humans}{2}{subsection.1.2.1}}
\citation{Bake_Saxe_Tene_2011}
\@writefile{brf}{\backcite{Thrun_Burgard_Fox_2005}{{3}{1.2.1}{subsection.1.2.1}}}
\@writefile{brf}{\backcite{Bake_Saxe_Tene_2011}{{3}{1.2.1}{subsection.1.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Non-parametric Bayesian state space filter}{3}{subsection.1.2.2}}
\citation{rai2013learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Reinforcement learning in belief space}{4}{subsection.1.2.3}}
\@writefile{brf}{\backcite{rai2013learning}{{4}{1.2.3}{subsection.1.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis outline}{4}{section.1.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Decisions under Uncertainty}{5}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Decision theory}{6}{subsection.2.1.1}}
\citation{Bernoulli1954}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces ad\relax }}{7}{figure.caption.1}}
\@writefile{brf}{\backcite{Bernoulli1954}{{7}{2.1.1}{figure.caption.1}}}
\citation{VonNeumann1944}
\newlabel{eq:exp_utility}{{2.1.1}{8}{Decision theory}{figure.caption.1}{}}
\@writefile{brf}{\backcite{VonNeumann1944}{{8}{2.1.1}{figure.caption.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Beliefs \& desires}{8}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Sequential decision process}{8}{section.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Definition of common variables used.\relax }}{9}{table.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:notation}{{2.1}{9}{Definition of common variables used.\relax }{table.caption.2}{}}
\newlabel{eq:joint_state_actions_util}{{2.1}{10}{Sequential decision process}{equation.2.2.1}{}}
\newlabel{fig:mdp_off}{{2.2(a)}{11}{Subfigure 2 2.2(a)}{subfigure.2.2.1}{}}
\newlabel{sub@fig:mdp_off}{{(a)}{11}{Subfigure 2 2.2(a)\relax }{subfigure.2.2.1}{}}
\newlabel{fig:mdp_on}{{2.2(b)}{11}{Subfigure 2 2.2(b)}{subfigure.2.2.2}{}}
\newlabel{sub@fig:mdp_on}{{(b)}{11}{Subfigure 2 2.2(b)\relax }{subfigure.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Dynamical Bayesian Network of a Markov Decision Process; it encodes the temporal relation between the random variables (circles), utilities (diamond) and decisions (squares). The arrows specify conditional distributions. In \textbf  {(a)} the decision nodes are not considered random variables whilst in \textbf  {(b)} they are. From these two DBN we can read off two conditional distributions, the state transition distribution (in red) and the action distribution (in purple). \relax }}{11}{figure.caption.3}}
\newlabel{fig:mdp}{{2.2}{11}{Dynamical Bayesian Network of a Markov Decision Process; it encodes the temporal relation between the random variables (circles), utilities (diamond) and decisions (squares). The arrows specify conditional distributions. In \textbf {(a)} the decision nodes are not considered random variables whilst in \textbf {(b)} they are. From these two DBN we can read off two conditional distributions, the state transition distribution (in red) and the action distribution (in purple). \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {off-policy}}}{11}{figure.caption.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {on-policy}}}{11}{figure.caption.3}}
\newlabel{eq:joint_state_actions}{{2.2}{11}{Sequential decision process}{equation.2.2.2}{}}
\newlabel{eq:temporal_expected_utility}{{2.4}{11}{Sequential decision process}{equation.2.2.4}{}}
\newlabel{eq:max_util}{{2.2}{11}{Sequential decision process}{equation.2.2.4}{}}
\newlabel{eq:expansion}{{2.5}{11}{Sequential decision process}{equation.2.2.5}{}}
\newlabel{eq:bellman}{{2.6}{12}{Sequential decision process}{equation.2.2.6}{}}
\newlabel{eq:on_policy_bellman}{{2.7}{12}{Sequential decision process}{equation.2.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}POMDP}{13}{subsection.2.2.1}}
\newlabel{eq:sensor}{{2.8}{13}{POMDP}{equation.2.2.8}{}}
\newlabel{eq:likelihood}{{2.9}{13}{POMDP}{equation.2.2.9}{}}
\newlabel{fig:motion_update}{{2.3(a)}{14}{Subfigure 2 2.3(a)}{subfigure.2.3.1}{}}
\newlabel{sub@fig:motion_update}{{(a)}{14}{Subfigure 2 2.3(a)\relax }{subfigure.2.3.1}{}}
\newlabel{fig:measurement}{{2.3(b)}{14}{Subfigure 2 2.3(b)}{subfigure.2.3.2}{}}
\newlabel{sub@fig:measurement}{{(b)}{14}{Subfigure 2 2.3(b)\relax }{subfigure.2.3.2}{}}
\newlabel{fig:likelihood}{{2.3(c)}{14}{Subfigure 2 2.3(c)}{subfigure.2.3.3}{}}
\newlabel{sub@fig:likelihood}{{(c)}{14}{Subfigure 2 2.3(c)\relax }{subfigure.2.3.3}{}}
\newlabel{fig:measurement_update}{{2.3(d)}{14}{Subfigure 2 2.3(d)}{subfigure.2.3.4}{}}
\newlabel{sub@fig:measurement_update}{{(d)}{14}{Subfigure 2 2.3(d)\relax }{subfigure.2.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \textbf  {(a)} An agent is located to the south west of a brick wall, it is equipped with a range sensor. The agent takes a forward action, but skids which results in a high increase of the uncertainty.\textbf  {(b)} The agent takes a measurement, $y_0$, of this distance to the wall; because his sensor is noisy his estimate is off. \textbf  {(c)} The agent uses with his measurement model to evaluate the plausibility of all locations in the world which would result in a similar measurement; illustrated by the likelihood function $p(y_0|x_0)$. \textbf  {(d)} The likelihood is integrated into the probability density function; $p(x_0|y_0) \propto p(y_0|x)p(x_0)$.\relax }}{14}{figure.caption.4}}
\newlabel{fig:belief_update_example}{{2.3}{14}{\textbf {(a)} An agent is located to the south west of a brick wall, it is equipped with a range sensor. The agent takes a forward action, but skids which results in a high increase of the uncertainty.\textbf {(b)} The agent takes a measurement, $y_0$, of this distance to the wall; because his sensor is noisy his estimate is off. \textbf {(c)} The agent uses with his measurement model to evaluate the plausibility of all locations in the world which would result in a similar measurement; illustrated by the likelihood function $p(y_0|x_0)$. \textbf {(d)} The likelihood is integrated into the probability density function; $p(x_0|y_0) \propto p(y_0|x)p(x_0)$.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{14}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{14}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{14}{figure.caption.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{14}{figure.caption.4}}
\newlabel{eq:motion_update}{{2.10}{15}{POMDP}{equation.2.2.10}{}}
\newlabel{eq:measurement_update}{{2.11}{15}{POMDP}{equation.2.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Bayesian state space filter.\relax }}{15}{figure.caption.5}}
\newlabel{fig:sub_pomdp}{{2.5(a)}{16}{Subfigure 2 2.5(a)}{subfigure.2.5.1}{}}
\newlabel{sub@fig:sub_pomdp}{{(a)}{16}{Subfigure 2 2.5(a)\relax }{subfigure.2.5.1}{}}
\newlabel{fig:sub_bmdp}{{2.5(b)}{16}{Subfigure 2 2.5(b)}{subfigure.2.5.2}{}}
\newlabel{sub@fig:sub_bmdp}{{(b)}{16}{Subfigure 2 2.5(b)\relax }{subfigure.2.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces \textbf  {(a)} POMDP graphical model. The state space, $X$, is hidden, but is still partially observable through a measurement, $Y$. \textbf  {(b)} belief-MDP, the POMDP is cast into a belief Markov Decision Process. The state space is a probability distribution, $b(x_t) = p(x_t)$, (known as a belief state) and is no longer considered a latent state. The original state transition function $p(x_{t+1}|x_t,a_t)$ is replaced by a belief state transition, $p(b_{t+1}|b_t,a_t)$. The reward is now a function of the belief.\relax }}{16}{figure.caption.6}}
\newlabel{fig:pomdp}{{2.5}{16}{\textbf {(a)} POMDP graphical model. The state space, $X$, is hidden, but is still partially observable through a measurement, $Y$. \textbf {(b)} belief-MDP, the POMDP is cast into a belief Markov Decision Process. The state space is a probability distribution, $b(x_t) = p(x_t)$, (known as a belief state) and is no longer considered a latent state. The original state transition function $p(x_{t+1}|x_t,a_t)$ is replaced by a belief state transition, $p(b_{t+1}|b_t,a_t)$. The reward is now a function of the belief.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{16}{figure.caption.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{16}{figure.caption.6}}
\newlabel{eq:belief_bellman}{{2.15}{16}{POMDP}{equation.2.2.15}{}}
\citation{Sondik_1973}
\citation{Thrun_2005}
\citation{Kaelbling_1998}
\newlabel{eq:belief_state_transformation}{{2.16}{17}{POMDP}{equation.2.2.16}{}}
\newlabel{eq:max_component}{{2.17}{17}{POMDP}{equation.2.2.17}{}}
\newlabel{eq:final_belief_bellman}{{2.18}{17}{POMDP}{equation.2.2.18}{}}
\@writefile{brf}{\backcite{Sondik_1973}{{17}{2.2.1}{equation.2.2.18}}}
\@writefile{brf}{\backcite{Thrun_2005}{{17}{2.2.1}{equation.2.2.18}}}
\citation{Thrun_2005}
\citation{PBVI}
\citation{HSV}
\citation{HSVI2}
\citation{FSVI}
\citation{SARSOP}
\citation{POMDP_approach_2010}
\@writefile{brf}{\backcite{Kaelbling_1998}{{18}{2.2.1}{equation.2.2.18}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}State of the art}{18}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Point-based Value Iteration}{18}{subsection.2.3.1}}
\@writefile{brf}{\backcite{Thrun_2005}{{18}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{PBVI}{{18}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{HSV}{{18}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{HSVI2}{{18}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{FSVI}{{18}{2.3.1}{subsection.2.3.1}}}
\citation{Spaan05icra}
\citation{PBVI_C_2006}
\citation{solving_continous_pomdps_2013}
\citation{Ross08onlineplanning}
\@writefile{brf}{\backcite{SARSOP}{{19}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{POMDP_approach_2010}{{19}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{Spaan05icra}{{19}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{PBVI_C_2006}{{19}{2.3.1}{subsection.2.3.1}}}
\@writefile{brf}{\backcite{solving_continous_pomdps_2013}{{19}{2.3.1}{subsection.2.3.1}}}
\citation{MC-POMDP}
\citation{Tree_batch_2005}
\citation{mc_update_ppomdps}
\citation{DRQ_AAAI_2015}
\citation{mnih-dqn-2015}
\citation{neura_fqi_2005}
\citation{belief_compression_2005}
\citation{bs_compression_2010}
\citation{next_best_touch}
\citation{CostalNavigation1999}
\citation{Roy99coastalnavigation}
\citation{Pegasus_2000}
\citation{dmp_seq_2012}
\citation{dmp_iros_2011}
\citation{dense_entropy_icra_2014}
\citation{Uncer_reduction_heuristic_2015}
\citation{Sol_POMDP_Policy_space_1998}
\citation{sigma_hull_iros_2013}
\citation{int_motion_planning_2013}
\@writefile{brf}{\backcite{Ross08onlineplanning}{{20}{2.3.1}{subsection.2.3.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Parametric Value Iteration}{20}{subsection.2.3.2}}
\@writefile{brf}{\backcite{MC-POMDP}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{Tree_batch_2005}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{mc_update_ppomdps}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{DRQ_AAAI_2015}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{mnih-dqn-2015}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{belief_compression_2005}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{bs_compression_2010}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{next_best_touch}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{CostalNavigation1999}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{brf}{\backcite{Roy99coastalnavigation}{{20}{2.3.2}{subsection.2.3.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Policy search}{20}{subsection.2.3.3}}
\@writefile{brf}{\backcite{Pegasus_2000}{{20}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{dmp_seq_2012}{{20}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{dmp_iros_2011}{{20}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{dense_entropy_icra_2014}{{20}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{Uncer_reduction_heuristic_2015}{{20}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{Sol_POMDP_Policy_space_1998}{{20}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{sigma_hull_iros_2013}{{20}{2.3.3}{subsection.2.3.3}}}
\citation{Quadrator_2008}
\citation{BelRoadMap_2009}
\citation{non_gauss_bel_plan_2012}
\citation{active_RSS_07}
\citation{plan_cont_bel_space_2015}
\citation{rob_online_bs_icra_2014}
\citation{bel_roadmap_2009}
\citation{plattRSS10}
\citation{Erez10ascalable}
\citation{van_den_Berg_2012}
\citation{Platt-RSS-10}
\citation{u_aware_grasp_ICRA_2015}
\citation{learn_grasp_un_icra_2011}
\citation{seq_traj_replan_iros_2013}
\citation{Li_2015}
\citation{un_water_inspection_icra_2012}
\citation{Bayesian_explor_exploit_2009}
\citation{Macro_uncertainty_2011}
\@writefile{brf}{\backcite{int_motion_planning_2013}{{21}{2.3.3}{subsection.2.3.3}}}
\@writefile{toc}{\contentsline {subsubsection}{Planning}{21}{section*.7}}
\@writefile{brf}{\backcite{Quadrator_2008}{{21}{2.3.3}{section*.7}}}
\@writefile{brf}{\backcite{BelRoadMap_2009}{{21}{2.3.3}{section*.7}}}
\@writefile{brf}{\backcite{non_gauss_bel_plan_2012}{{21}{2.3.3}{section*.7}}}
\@writefile{brf}{\backcite{active_RSS_07}{{21}{2.3.3}{section*.7}}}
\@writefile{brf}{\backcite{plan_cont_bel_space_2015}{{21}{2.3.3}{section*.7}}}
\@writefile{brf}{\backcite{rob_online_bs_icra_2014}{{21}{2.3.3}{section*.7}}}
\@writefile{brf}{\backcite{bel_roadmap_2009}{{21}{2.3.3}{section*.7}}}
\@writefile{toc}{\contentsline {subsubsection}{Optimal control}{21}{section*.8}}
\@writefile{brf}{\backcite{plattRSS10}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{Erez10ascalable}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{van_den_Berg_2012}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{Platt-RSS-10}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{u_aware_grasp_ICRA_2015}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{learn_grasp_un_icra_2011}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{seq_traj_replan_iros_2013}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{Li_2015}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{un_water_inspection_icra_2012}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{Bayesian_explor_exploit_2009}{{21}{2.3.3}{section*.8}}}
\@writefile{brf}{\backcite{Macro_uncertainty_2011}{{21}{2.3.3}{section*.8}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Summary}{21}{section.2.4}}
\bibstyle{plainnat}
\bibdata{bib/RL.bib,bib/pomdp.bib,bib/cpomdp.bib,bib/citations.bib,bib/DT.bib,bib/ToM.bib,bib/ProspectTheory.bib}
\bibcite{rob_online_bs_icra_2014}{{1}{2014}{{a.~Agha-mohammadi et~al.}}{{a.~Agha-mohammadi, Agarwal, Mahadevan, Chakravorty, Tomkins, Denny, and Amato}}}
\bibcite{Bake_Saxe_Tene_2011}{{2}{2011}{{Bake et~al.}}{{Bake, Tenenbaum, and Saxe}}}
\bibcite{Bernoulli1954}{{3}{1954}{{Bernoulli}}{{}}}
\bibcite{Billard08chapter}{{4}{2008}{{Billard et~al.}}{{Billard, Calinon, Dillmann, and Schaal}}}
\bibcite{solving_continous_pomdps_2013}{{5}{2013}{{Brechtel et~al.}}{{Brechtel, Gindele, and Dillmann}}}
\bibcite{mc_update_ppomdps}{{6}{2011}{{Brooks and Williams}}{{}}}
\bibcite{ActingUncertainty_1996}{{7}{1996}{{Cassandra et~al.}}{{Cassandra, Kaelbling, and Kurien}}}
\bibcite{u_aware_grasp_ICRA_2015}{{8}{2015}{{Chen and von Wichert}}{{}}}
\bibcite{POMDP_approach_2010}{{9}{2010}{{Du et~al.}}{{Du, Hsu, Kurniawati, Lee, Ong, and Png}}}
\@writefile{toc}{\contentsline {chapter}{References}{23}{chapter*.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{Erez10ascalable}{{10}{2010}{{Erez and Smart}}{{}}}
\bibcite{Tree_batch_2005}{{11}{2005}{{Ernst et~al.}}{{Ernst, Geurts, and Wehenkel}}}
\bibcite{Sol_POMDP_Policy_space_1998}{{12}{1998}{{Hansen}}{{}}}
\bibcite{DRQ_AAAI_2015}{{13}{2015}{{Hausknecht and Stone}}{{}}}
\bibcite{Quadrator_2008}{{14}{2008}{{He et~al.}}{{He, Prentice, and Roy}}}
\bibcite{Macro_uncertainty_2011}{{15}{2011}{{He et~al.}}{{He, Brunskill, and Roy}}}
\bibcite{next_best_touch}{{16}{2013}{{Hebert et~al.}}{{Hebert, Howard, Hudson, Ma, and Burdick}}}
\bibcite{un_water_inspection_icra_2012}{{17}{2012}{{Hollinger et~al.}}{{Hollinger, Englot, Hover, Mitra, and Sukhatme}}}
\bibcite{plan_cont_bel_space_2015}{{18}{2015}{{Indelman et~al.}}{{Indelman, Carlone, and Dellaert}}}
\bibcite{int_motion_planning_2013}{{19}{2013}{{Kaelbling and Lozano-P{\'e}rez}}{{}}}
\bibcite{Kaelbling_1998}{{20}{1998}{{Kaelbling et~al.}}{{Kaelbling, Littman, and Cassandra}}}
\bibcite{SARSOP}{{21}{2008}{{Kurniawati et~al.}}{{Kurniawati, Hsu, and Lee}}}
\bibcite{sigma_hull_iros_2013}{{22}{2013}{{Lee et~al.}}{{Lee, Duan, Patil, Schulman, McCarthy, van~den Berg, Goldberg, and Abbeel}}}
\bibcite{Li_2015}{{23}{2016}{{Li et~al.}}{{Li, Hang, Kragic, and Billard}}}
\bibcite{bs_compression_2010}{{24}{2010}{{Li et~al.}}{{Li, Cheung, and Liu}}}
\bibcite{active_RSS_07}{{25}{2007}{{Martinez-Cantin et~al.}}{{Martinez-Cantin, de~Freitas, Doucet, and Castellanos}}}
\bibcite{Bayesian_explor_exploit_2009}{{26}{2009}{{Martinez-Cantin et~al.}}{{Martinez-Cantin, de~Freitas, Brochu, Castellanos, and Doucet}}}
\bibcite{mnih-dqn-2015}{{27}{2015}{{Mnih et~al.}}{{Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare, Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik, Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis}}}
\bibcite{Pegasus_2000}{{28}{2000}{{Ng and Jordan}}{{}}}
\bibcite{PBVI}{{29}{2003}{{Pineau et~al.}}{{Pineau, Gordon, and Thrun}}}
\bibcite{Platt-RSS-10}{{30}{2010{a}}{{Platt et~al.}}{{Platt, Tedrake, Kaelbling, and Lozano-Perez}}}
\bibcite{non_gauss_bel_plan_2012}{{31}{2012}{{Platt et~al.}}{{Platt, Kaelbling, Lozano-Perez, and Tedrake}}}
\bibcite{plattRSS10}{{32}{2010{b}}{{Platt et~al.}}{{Platt, Tedrake, Kaelbling, and Lozano-P\'{e}rez}}}
\bibcite{PBVI_C_2006}{{33}{2006}{{Porta et~al.}}{{Porta, Vlassis, Spaan, and Poupart}}}
\bibcite{BelRoadMap_2009}{{34}{2009{a}}{{Prentice and Roy}}{{}}}
\bibcite{bel_roadmap_2009}{{35}{2009{b}}{{Prentice and Roy}}{{}}}
\bibcite{rai2013learning}{{36}{2013}{{Rai et~al.}}{{Rai, De~Chambrier, and Billard}}}
\bibcite{Sondik_1973}{{37}{1973}{{Richard D.~Smallwood}}{{}}}
\bibcite{Ross08onlineplanning}{{38}{2008}{{Ross et~al.}}{{Ross, Pineau, Paquet, and Chaib-draa}}}
\bibcite{CostalNavigation1999}{{39}{1999}{{Roy et~al.}}{{Roy, Burgard, Fox, and Thrun}}}
\bibcite{belief_compression_2005}{{40}{2000}{{Roy}}{{}}}
\bibcite{Roy99coastalnavigation}{{41}{1999}{{Roy and Thrun}}{{}}}
\bibcite{HSV}{{42}{2004}{{Smith and Simmons}}{{}}}
\bibcite{HSVI2}{{43}{2012}{{Smith and Simmons}}{{}}}
\bibcite{Spaan05icra}{{44}{2005}{{Spaan and Vlassis}}{{}}}
\bibcite{learn_grasp_un_icra_2011}{{45}{2011{a}}{{Stulp et~al.}}{{Stulp, Theodorou, Buchli, and Schaal}}}
\bibcite{dmp_iros_2011}{{46}{2011{b}}{{Stulp et~al.}}{{Stulp, Theodorou, Kalakrishnan, Pastor, Righetti, and Schaal}}}
\bibcite{dmp_seq_2012}{{47}{2012}{{Stulp et~al.}}{{Stulp, Theodorou, and Schaal}}}
\bibcite{MC-POMDP}{{48}{2000}{{Thrun}}{{}}}
\bibcite{Thrun_2005}{{49}{2005{a}}{{Thrun et~al.}}{{Thrun, Burgard, and Fox}}}
\bibcite{Thrun_Burgard_Fox_2005}{{50}{2005{b}}{{Thrun et~al.}}{{Thrun, Burgard, and Fox}}}
\bibcite{dense_entropy_icra_2014}{{51}{2014}{{Vallve and Andrade{-}Cetto}}{{}}}
\bibcite{van_den_Berg_2012}{{52}{2012}{{van~den Berg et~al.}}{{van~den Berg, Patil, and Alterovitz}}}
\bibcite{FSVI}{{53}{2007}{{Veloso}}{{}}}
\bibcite{VonNeumann1944}{{54}{1990}{{Von~Neumann and Morgenstern}}{{}}}
\bibcite{Uncer_reduction_heuristic_2015}{{55}{2015}{{Zhang et~al.}}{{Zhang, Rekleitis, and Dudek}}}
\bibcite{seq_traj_replan_iros_2013}{{56}{2013}{{Zito et~al.}}{{Zito, Kopicki, Stolkin, Borst, Schmidt, Roa, and Wyatt}}}
