%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter 0: Preamble
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\graphicspath{{figures/ch0/}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\lettrine[lines=2]{D}{ecision} making and planning with partial state information is a problem faced 
by all forms of intelligent entities being either virtual, synthetic or biological. The formulation of 
a problem under partial state information leads to an exorbitant set of choices with associated 
probabilistic outcomes making its resolution difficult when using traditional planning methods. 
Human beings have acquired the ability of acting under uncertainty through education and self-learning. 
Transferring our know-how to artificial agents and robots will make it faster for them to learn and even improve upon us in
tasks in which incomplete knowledge is available, which is the objective of this thesis.

A large body of scientific work has focused on transferring behaviour from humans to robots via Programming by Demonstration frameworks which focus on learning how to imitate human behaviour. Tasks such as ``pick and place'', hitting motions, and bipedal locomotion have been encoded 
through either symbolic, statistical or dynamical system representations. In contrast there has been less focus on transferring higher cognitive behaviour such as
problem solving skills and search strategies from humans to robots.

This thesis aims to model how humans reason with respect to their beliefs and the role uncertainty plays during spatial navigation search tasks. 
We consider for instance tasks such as localising  an object in a room or connection a plug to a power socket in the dark, 
or any such situation with total suppression of visual information, and transfer this reasoning mechanisms to a robot apprentice. 
There are many robotic application domains in which uncertainty resulting from a lack of visual perception is common, such as in underwater 
maintenance, planetary exploration and occluded manipulation tasks. Learning human search models and transferring them to robots is useful
in such domains and learning a search strategy from scratch would prove intractable.

A difficulty in learning humans reasoning mechanisms, in the search scenarios we consider, is that
the humans beliefs and sensations (haptic and tactile) are unobservable and they vary within and
across subjects. We infer the human sensations from either the kinematic relationship between them
and a known geometric description of the environment or the human subjects use a tool equipped with
a sensor (force-torque sensor) whose measurements are used to infer the human sensations. The actual
sensations, which are a function of either the sensor tool or kinematic-environment measurements, are
transformed to a binary feature vector which encodes whether contact are present between features
such as surfaces, edges and corners of the environment.

We model the human's beliefs by a probability density function which we update through recursive Bayesian 
state space estimation using motion estimates, acquired through a tracking system (the human subjects wore markers), 
and the sensation estimates were obtained as described above. We make the assumption that the probability 
density function, representing the human's belief, is updated by a Bayesian recursion and that this process is similar to the way in 
which humans integrate information.

To model the reasoning processes of human subjects performing the search tasks we learn a generative joint distribution over beliefs
and actions (end-effector velocities) which were recorded during the executions of the task. 
The high dimensionality of the belief and its varying complexity  during the searches required that we compress the 
belief to its most likely state and entropy. 

We evaluate this methodology of learning search strategies in a task consisting of finding an object on a table. 
We demonstrate that multiple search strategies are encoded in the joint belief-action distribution and 
we compare this approach with greedy myopic and coastal navigation search algorithms. The results show that the human learned 
search model is the fastest of all methods.

We consider in a second setting a task in which human subjects have to demonstrate how 
to search for and connect a plug to a power socket to a robot apprentice deprived of visual information. 
We take the same approach but incorporate the learning of the policy into a reinforcement learning framework 
and demonstrate that by defining a simple cost function the quality of the final learned policy can be significantly
improved without the need of performing exploratory rollouts which are costly and typically necessary in RL.

Both search tasks above can be considered as active localisation in the sense that uncertainty
originates from the position of the human or robot in the world. We now consider search setting
in which both the position of the robot and and aspects of environment are uncertain. Given the
unstructured nature of the belief a histogram parametrisation of the joint distribution over the
robot and the environment is necessary. However, naively doing so becomes quickly intractable as
the computational cost is exponential in terms of the parametrisation. We demonstrate that by
only parametrising the marginals and by memorising the parameters of the measurement likelihood
functions we can recover the exact same solution as the naive parametrisations at a cost which is
linear in space and time complexity as oppose to exponential.

\mylineskip

\noindent\textsc{\textbf{Keywords:}} Programming by Demonstration, POMDP, Reinforcement Learning, State Space Estimation (SSE)
\end{abstract}

\begin{resume}
\lettrine[lines=2]{R}{aisonner} et prendre des décisions pour résoudre des problèmes avec une information partielle est une difficulté  à laquelle doit faire 
face tous êtres : virtuels, synthétiques ou biologiques. Les tentatives de résolution d'un tel problème où l'information spatial  est partielle débouche sur à un nombre 
d'actions possibles exorbitant qui tous ont des probabilités différentes de succès. Ceci rend la résolution de tels problèmes difficile quand des méthodes de planning traditionnelles sont employées.  
Les humains ont acquis une habilitées à agir dans ces situations où l'incertitude est omniprésente par l'éducation et l'auto-apprentissage. Transférer ce savoir-faire à des intelligences 
artificielles ou à des robots augmenteraient leurs habilités à résoudre des tâches qui sont partiellement spécifiées et donc où l'incertitude règne.

Un grand nombre de travaux scientifiques ont mis l'accent sur le transfer du comportement humain aux robots via la programmation par apprentissage. Cette méthode permet 
au robot d'apprendre à imiter les comportements humains. Des tâches contenants des éléments telles que la manipulation d'objets ou la locomotion bipède ont été encodées 
soit par des fonctions symboliques, statistiques ou dynamiques.  Par contre, il y a moins d'exemple de transfert de comportement cognitif de plus haut niveaux aux robots, comme 
les compétences en résolution de problèmes et les stratégies d'exploration.

L'objectif de ce mémoire est de créer des modèles mathématiques correspondant au raisonnement humain à l'égard de l'incertitude présente durant des tâches d'exploration dans le domaine de la navigation spatial sans information visuelle. Ces modèles de raisonnement sont transférés à un robot apprenti. Cette méthode évite un long apprentissage de notre savoir au robot. 
Le choix de la navigation spatial sans information visuelle a été motivée par le fait qu'il existe de nombreux domaines d'application robotique où l'incertitude résultante d'une absence de perception visuelle est fréquente,  comme : l'entretien des fonds marins, l'exploration planétaire et des tâches de manipulation avec des occlusions fréquentes.
Pour ce travail les scénarios suivants sont étudiés :  la localisation d'un objet dans une pièce et l'établissement d'une connexion  avec une prise électrique. 
Une difficulté présente dans l'apprentissage du raisonnement humain, dans les scénarios de recherche que nous considérons, est que nos pensées et sensations (haptique et tactile) 
sont inobservables et varient entre les personnes. Nous déduisons les sensations perçues des  humaines en observant leurs réactions cinématiques en fonction de la géométrique de l'environnement. 
Ou encore les sujets humains utilisent un outil équipé d'un capteur de force dont les mesures sont utilisées pour déduire leurs sensations. Ces mesures sont ensuite transformées en un vecteur binaire 
qui est générique pour toutes les tâches que nous considérons.

Les données ainsi obtenues sont utilisée pour modéliser les pensées humaines par une fonction de densité de probabilité que nous actualisons via une estimation bayésienne récursive; l'hypothèse est 
que la fonction de densité de probabilité actualisée par une fonction bayésienne récursive est similaire au processus humain pour intégrer des informations en continu.
La modélisation des processus de raisonnement des sujets humains effectuant les tâches exploratoires nous apprend une distribution conjointe des pensées et actions (vitesses de l'effecteur) 
qui ont été enregistrées au cours de l'exécution de la démonstration. La dimensionnalité élevée de l'état de la pensé et de sa complexité exige sa simplification aux états les plus probables 
tout en conservant l'information de l'entropie. Les résultats montrent que le rebot effectue plus effectivement ses tâches qu'avec les méthodes traditionnelles. 
Nous considérons une deuxième tâche qui consiste à connecter une fiche à une prise électrique. Nous prenons la même approche, que nous perfectionnons en intégrant un 
système automatique de renforcement d'apprentissage. Nous démontrons qu'une simple fonction objective des coûts de la qualité améliore significativement les capacités du robot.

Les deux tâches d'exploration mentionnées ci-dessus peuvent être considérées comme des problèmes de localisation-actif où l'incertitude est uniquement présente dans la relation 
entre la position de l'humain vis-à-vis du cadre de référence, le monde. Nous considérons maintenant un problème d'exploration où l'incertitude se trouve à la fois dans la position du robot (ou l'humain) 
et dans des aspects de l'environnement  comme la position d'objets. Étant donné la nature non structurée de l'incertitude un histogramme est choisi pour paramétrer la distribution conjointe 
des positions du robot et de l'environnement. Cependant, cette paramétrisation devient rapidement intenable comme le coût de résolution devient exponentiel en termes du nombre de paramètre.  
Nous démontrons qu'en utilisant seulement les paramètres de marginales et en mémorisant les paramètres des fonctions de mesure nous pouvons reproduire la même solution que la paramétrisation de l'histogramme 
à une complexité linéaire (espace et temps) contre une exponentielle.



\mylineskip

\noindent\textsc{\textbf{Mots-clés:}} Programmation par démonstration, POMDP, Reinforcement Learning, Modèle espace d'états
\end{resume}
%


%\begin{dedication}
%\emph{Dedication\\ here}
%\end{dedication}
%\forcenewpage
%\chapter*{Acknowledgments}
%Acknowledgements here