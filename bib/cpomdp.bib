@incollection{mc_update_ppomdps,
year={2011},
isbn={978-3-642-14742-5},
booktitle={Robotics Research},
volume={66},
series={Springer Tracts in Advanced Robotics},
editor={Kaneko, Makoto and Nakamura, Yoshihiko},
doi={10.1007/978-3-642-14743-2_19},
title={A Monte Carlo Update for Parametric POMDPs},
url={http://dx.doi.org/10.1007/978-3-642-14743-2_19},
publisher={Springer Berlin Heidelberg},
author={Brooks, Alex and Williams, Stefan},
pages={213-223},
language={English}
}

@INPROCEEDINGS{Erez10ascalable,
    author = {Tom Erez and William D. Smart},
    title = {A Scalable Method for Solving High-Dimensional Continuous POMDPs Using Local Approximation},
    booktitle = {Conf. on Uncertainty in Artificial Intelligence},
    year = {2010}
}

@incollection{MCVI_CS_POMDPs,
year={2011},
isbn={978-3-642-17451-3},
booktitle={Algorithmic Foundations of Robotics IX},
volume={68},
series={Springer Tracts in Advanced Robotics},
editor={Hsu, David and Isler, Volkan and Latombe, Jean-Claude and Lin, MingC.},
doi={10.1007/978-3-642-17452-0_11},
title={Monte Carlo Value Iteration for Continuous-State POMDPs},
url={http://dx.doi.org/10.1007/978-3-642-17452-0_11},
publisher={Springer Berlin Heidelberg},
author={Bai, Haoyu and Hsu, David and Lee, WeeSun and Ngo, VienA.},
pages={175-191},
language={English}
}

@incollection{NIPS2011_4477,
title = {Monte Carlo Value Iteration with Macro-Actions},
author = {Zhan Lim and Lee Sun and Daniel J. Hsu},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {1287--1295},
year = {2011},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4477-monte-carlo-value-iteration-with-macro-actions.pdf}
}

@inproceedings{solving_continous_pomdps_2013,
    Publisher = {JMLR Workshop and Conference Proceedings},
    Author = {Sebastian Brechtel and Tobias Gindele and RÃ¼diger Dillmann},
    Url = {http://jmlr.org/proceedings/papers/v28/brechtel13.pdf},
    Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
    Title = {Solving Continuous POMDPs: Value Iteration with Incremental Learning of an Efficient Space Representation},
    Month = may,
    Volume = {28},
    Editor = {Sanjoy Dasgupta and David Mcallester},
    Year = {2013},
    Pages = {370-378},
} 

@InProceedings{Spaan05icra,
  author =       {Matthijs T. J. Spaan and Nikos Vlassis},
  title =        {Planning with continuous actions in partially
                  observable environments},
  booktitle =    {Proceedings of the IEEE International Conference on
                  Robotics and Automation},
  pages =        {3469--3474},
  year =         2005,
  address =      {Barcelona, Spain}
}


@ARTICLE{PBVI_C_2006,
    author = {Josep M. Porta and Nikos Vlassis and Matthijs T. J. Spaan and Pascal Poupart},
    title = {Point-Based Value Iteration for Continuous POMDPs},
    journal = {JOURNAL OF MACHINE LEARNING RESEARCH},
    year = {2006},
    volume = {7},
    pages = {2329--2367}
}

@InProceedings{MC-POMDP,
  author =       "Thrun, Sebastian",
  title =        "Monte Carlo {POMDP}s",
  booktitle =    "Advances in Neural Information Processing Systems (NIPS 1999)",
  year =         "2000",
  ISBN =         "0-262-19450-3",
  editor =    "Solla, Sara A. and Leen, Todd K. and M{\"u}ller, Klaus-Robert ",
  publisher = "MIT Press",
  pages =     "1064--1070",
  url = "http://robots.stanford.edu/papers/thrun.mcpomdp.pdf",
  bib2html_rescat = "Partial Observability",
}

@INPROCEEDINGS{Porta05robotplanning,
    author = {Josep M. Porta and Matthijs T. J. Spaan and Nikos Vlassis},
    title = {Robot planning in partially observable continuous domains},
    booktitle = {In Robotics: Science and Systems I},
    year = {2005},
    pages = {217--224}
}


@article{PPOMDP_2006,
title = "Parametric \{POMDPs\} for planning in continuous state spaces ",
journal = "Robotics and Autonomous Systems ",
volume = "54",
number = "11",
pages = "887 - 897",
year = "2006",
note = "Planning Under Uncertainty in Robotics ",
issn = "0921-8890",
doi = "http://dx.doi.org/10.1016/j.robot.2006.05.007",
url = "http://www.sciencedirect.com/science/article/pii/S0921889006000960",
author = "Alex Brooks and Alexei Makarenko and Stefan Williams and Hugh Durrant-Whyte",
}


%% Belief space planning

@inproceedings{bsp_rss_2010a,
    author = {Robert Platt and Russell Tedrake and Leslie Kaelbling and Tom\'{a}s Lozano-P\'{e}rez},
    title = {Belief space planning assuming maximum likelihood observations}, 
    booktitle = {Robotics Science and Systems Conference (RSS)},
    year = {2010},
    keywords={Belief Space Planning},
    url = {http://groups.csail.mit.edu/robotics-center/public_papers/Platt10.pdf}
}

@INPROCEEDINGS{rob_online_bs_icra_2014,
author={A. a. Agha-mohammadi and S. Agarwal and A. Mahadevan and S. Chakravorty and D. Tomkins and J. Denny and N. M. Amato},
booktitle={Robotics and Automation (ICRA), 2014 IEEE International Conference on},
title={Robust online belief space planning in changing environments: Application to physical mobile robots},
year={2014},
pages={149-156},
doi={10.1109/ICRA.2014.6906602},
month={May},}


@article{plan_cont_bel_space_2015,
author = {Indelman, Vadim and Carlone, Luca and Dellaert, Frank}, 
title = {Planning in the continuous domain: A generalized belief space approach for autonomous navigation in unknown environments},
volume = {34}, 
number = {7}, 
pages = {849-882}, 
year = {2015}, 
doi = {10.1177/0278364914561102}, 
URL = {http://ijr.sagepub.com/content/34/7/849.abstract}, 
eprint = {http://ijr.sagepub.com/content/34/7/849.full.pdf+html}, 
journal = {The International Journal of Robotics Research} 
}

@article{bel_roadmap_2009,
author = {Prentice, Samuel and Roy, Nicholas}, 
title = {The Belief Roadmap: Efficient Planning in Belief Space by Factoring the Covariance},
volume = {28}, 
number = {11-12}, 
pages = {1448-1465}, 
year = {2009}, 
doi = {10.1177/0278364909341659}, 
abstract ={
	When a mobile agent does not know its position perfectly, incorporating the predicted uncertainty of future position estimates into the planning process can lead to substantially better motion performance. However, planning in the space of probabilistic position estimates, or belief space, can incur a substantial computational cost. In this paper, we show that planning in belief space can be performed efficiently for linear Gaussian systems by using a factored form of the covariance matrix. This factored form allows several prediction and measurement steps to be combined into a single linear transfer function, leading to very efficient posterior belief prediction during planning. We give a belief-space variant of the probabilistic roadmap algorithm called the belief roadmap (BRM) and show that the BRM can compute plans substantially faster than conventional belief space planning. We conclude with performance results for an agent using ultra-wide bandwidth radio beacons to localize and show that we can efficiently generate plans that avoid failures due to loss of accurate position estimation.
            }, 
URL = {http://ijr.sagepub.com/content/28/11-12/1448.abstract}, 
eprint = {http://ijr.sagepub.com/content/28/11-12/1448.full.pdf+html}, 
journal = {The International Journal of Robotics Research} 
}

@INPROCEEDINGS{FIRM_2011,
author={A. a. Agha-mohammadi and S. Chakravorty and N. M. Amato},
booktitle={Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on},
title={FIRM: Feedback controller-based information-state roadmap - A framework for motion planning under uncertainty},
year={2011},
pages={4284-4291},
keywords={Adaptive control;Aerospace electronics;Bismuth;History;Markov processes;Planning;Uncertainty},
doi={10.1109/IROS.2011.6095010},
ISSN={2153-0858},
month={Sept}
}


@INPROCEEDINGS{non_gauss_bel_plan_2012,
author={R. Platt and L. Kaelbling and T. Lozano-Perez and R. Tedrake},
booktitle={Robotics and Automation (ICRA), 2012 IEEE International Conference on},
title={Non-Gaussian belief space planning: Correctness and complexity},
year={2012},
pages={4711-4717},
keywords={Gaussian distribution;computational complexity;manipulators;optimisation;planning (artificial intelligence);Gaussian distribution;belief-space plan;complex information-gathering operations;computational complexity;nongaussian belief space planning;nonlinear optimization problem;partially observable control problem;probability distributions space;Algorithm design and analysis;Equations;Gaussian distribution;Measurement by laser beam;Planning;Robots;Trajectory},
doi={10.1109/ICRA.2012.6225223},
ISSN={1050-4729},
month={May}
}

@article{int_motion_planning_2013,
 author = {Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom\'{a}s},
 title = {Integrated Task and Motion Planning in Belief Space},
 journal = {Int. J. Rob. Res.},
 issue_date = {August-September 2013},
 volume = {32},
 number = {9-10},
 month = aug,
 year = {2013},
 issn = {0278-3649},
 pages = {1194--1227},
 numpages = {34},
 url = {http://dx.doi.org/10.1177/0278364913484072},
 doi = {10.1177/0278364913484072},
 acmid = {2528323},
 publisher = {Sage Publications, Inc.},
 address = {Thousand Oaks, CA, USA},
 keywords = {belief space, manipulation planning, mobile manipulation, planning under uncertainty, symbolic task planning},
} 



%% Local Search

@article{van_den_Berg_2012,
author = {van den Berg, Jur and Patil, Sachin and Alterovitz, Ron}, 
title = {Motion planning under uncertainty using iterative local optimization in belief space},
volume = {31}, 
number = {11}, 
pages = {1263-1278}, 
year = {2012}, 
doi = {10.1177/0278364912456319}, 
URL = {http://ijr.sagepub.com/content/31/11/1263.abstract}, 
eprint = {http://ijr.sagepub.com/content/31/11/1263.full.pdf+html}, 
journal = {The International Journal of Robotics Research} 
}


%  Heuristic

@inproceedings{dense_entropy_icra_2014,
  author    = {Joan Vallve and Juan Andrade{-}Cetto},
  title     = {Dense entropy decrease estimation for mobile robot exploration},
  booktitle = {2014 {IEEE} International Conference on Robotics and Automation, {ICRA}
               2014, Hong Kong, China, May 31 - June 7, 2014},
  pages     = {6083--6089},
  year      = {2014},
  doi       = {10.1109/ICRA.2014.6907755},
}

@INPROCEEDINGS{Uncer_reduction_heuristic_2015,
author={Q. Zhang and I. Rekleitis and G. Dudek},
booktitle={Computer and Robot Vision (CRV), 2015 12th Conference on},
title={Uncertainty Reduction via Heuristic Search Planning on Hybrid Metric/Topological Map},
year={2015},
pages={222-229},
keywords={Kalman filters;SLAM (robots);image sensors;intelligent robots;mobile robots;nonlinear filters;path planning;robot vision;topology;SLURM;bidirectional edge propagation simulation;camera sensor network;extended Kalman filter;heuristic search planning;hybrid metric/topological map;robotic system;simultaneous localization and uncertainty reduction;uncertainty reduction planning;Cost function;Heuristic algorithms;Measurement uncertainty;Planning;Robots;Uncertainty;Generalized Voronoi Graph;Heuristic search;Planning;SLAM;Uncertainty Reduction},
doi={10.1109/CRV.2015.36},
month={June}}


% Grasping


@INPROCEEDINGS{seq_traj_replan_iros_2013,
author={C. Zito and M. S. Kopicki and R. Stolkin and C. Borst and F. Schmidt and M. A. Roa and J. L. Wyatt},
booktitle={Intelligent Robots and Systems (IROS), 2013 IEEE/RSJ International Conference on},
title={Sequential trajectory re-planning with tactile information gain for dexterous grasping under object-pose uncertainty},
year={2013},
pages={4013-4020},
keywords={dexterous manipulators;tactile sensors;trajectory control;belief updating;dexterous grasping;grasp configuration;hierarchical probabilistic roadmap planning;high DoF manipulators;high degree of freedom manipulators;information gain planning;nonGaussian pose uncertainty;object-pose uncertainty;reach-to-grasp trajectories;sequential trajectory replanning;tactile information gain;tactile sensors;Grasping;Manipulators;Planning;Robot sensing systems;Trajectory;Uncertainty},
doi={10.1109/IROS.2013.6696930},
ISSN={2153-0858},
month={Nov}
}

@INPROCEEDINGS{learn_grasp_un_icra_2011,
author={F. Stulp and E. Theodorou and J. Buchli and S. Schaal},
booktitle={Robotics and Automation (ICRA), 2011 IEEE International Conference on},
title={Learning to grasp under uncertainty},
year={2011},
pages={5703-5708},
keywords={Boolean algebra;end effectors;learning (artificial intelligence);mobile robots;path planning;pose estimation;probability;state estimation;cost function;dynamic movement primitives;grasp planning;manipulation strategies;motion planning;object position;path integrals;probabilistic model free reinforcement learning algorithm policy improvement;robot learning;robust motion primitives;state estimation uncertainty distribution;Grasping;Planning;Robots;Robustness;State estimation;Trajectory;Uncertainty},
doi={10.1109/ICRA.2011.5979644},
ISSN={1050-4729},
month={May}
}


@INPROCEEDINGS{u_aware_grasp_ICRA_2015,
author={D. Chen and G. von Wichert},
booktitle={Robotics and Automation (ICRA), 2015 IEEE International Conference on},
title={An uncertainty-aware precision grasping process for objects with unknown dimensions},
year={2015},
pages={4312-4317},
keywords={actuators;closed loop systems;manipulators;planning;uncertain systems;actuation uncertainties;assembly tasks;closed loop control;dynamic process;grasp planning stage;manipulation tasks;object pose;packaging tasks;perceptual uncertainties;uncertainty-aware precision grasping process;unintended finger-object contacts;Grasping;Grippers;Predictive models;Robots;Robustness;Trajectory;Uncertainty},
doi={10.1109/ICRA.2015.7139794},
month={May}
}


@article{Li_2015,
title = "Dexterous grasping under shape uncertainty ",
journal = "Robotics and Autonomous Systems ",
volume = "75, Part B",
pages = "352 - 364",
year = "2016",
issn = "0921-8890",
doi = "http://dx.doi.org/10.1016/j.robot.2015.09.008",
url = "http://www.sciencedirect.com/science/article/pii/S0921889015001967",
author = "Miao Li and Kaiyu Hang and Danica Kragic and Aude Billard",
}


% 	Under Water Vehicles

@INPROCEEDINGS{un_water_inspection_icra_2012,
author={G. A. Hollinger and B. Englot and F. Hover and U. Mitra and G. S. Sukhatme},
booktitle={Robotics and Automation (ICRA), 2012 IEEE International Conference on},
title={Uncertainty-driven view planning for underwater inspection},
year={2012},
pages={4884-4891},
keywords={Bayes methods;autonomous underwater vehicles;control engineering computing;inspection;mesh generation;mobile robots;nonparametric statistics;optimisation;path planning;regression analysis;ships;solid modelling;sonar;uncertainty handling;3D meshes;3D model;AUV;active perception problems;anomaly detection;autonomous underwater vehicle;cost functions;experimental trials;formal property;inspection performance;nonparametric Bayesian regression;path planning;profiling sonar data;ship hull inspection;sonar-derived point clouds;submerged ship hull;submodular optimization;uncertainty modeling;uncertainty-driven view planning;underwater inspection;underwater structure inspection;watertight surfaces;Data models;Inspection;Marine vehicles;Surface reconstruction;Surface treatment;Uncertainty;Vectors},
doi={10.1109/ICRA.2012.6224726},
ISSN={1050-4729},
month={May},}



% Policy Search


@ARTICLE{dmp_seq_2012,
author={F. Stulp and E. A. Theodorou and S. Schaal},
journal={IEEE Transactions on Robotics},
title={Reinforcement Learning With Sequences of Motion Primitives for Robust Manipulation},
year={2012},
volume={28},
number={6},
pages={1360-1370},
keywords={control engineering computing;learning (artificial intelligence);manipulators;motion control;trajectory control;PI2 algorithm;manipulation tasks;motion primitive sequences;movement trajectory;path integrals;physical contact events;pick-and-place tasks;policy improvement;reinforcement learning;robust manipulation;Adaptive systems;Grasping;Learning;Learning systems;Manipulators;Learning and adaptive systems;manipulation planning;reinforcement learning},
doi={10.1109/TRO.2012.2210294},
ISSN={1552-3098},
month={Dec}
}

@InProceedings{sis_pomdp_2002,
  author =       "Aberdeen, Douglas and Baxter, Jonathan",
  title =        "Scaling Internal-State Policy-Gradient Methods for POMDPs",
  booktitle =    "Proceedings of the Nineteenth International Conference on Machine Learning (ICML 2002)",
  editor = "Sammut, Claude and Hoffman, Achim",
  year =         "2002",
  ISBN =         "1-55860-873-7",
  publisher = "Morgan Kauffman",
  address =   "San Francisco, CA, USA",
  pages =     "3--10",
  url = "http://users.rsise.anu.edu.au/~daa/files/papers/gradIstate-icml.pdf",
  bib2html_rescat = "Learning Methods, Partial Observability",
}


@inproceedings{Sol_POMDP_Policy_space_1998,
 author = {Hansen, Eric A.},
 title = {Solving POMDPs by Searching in Policy Space},
 booktitle = {Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'98},
 year = {1998},
 isbn = {1-55860-555-X},
 location = {Madison, Wisconsin},
 pages = {211--219},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2074094.2074119},
 acmid = {2074119},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Pegasus_2000,
 author = {Ng, Andrew Y. and Jordan, Michael},
 title = {PEGASUS: A Policy Search Method for Large MDPs and POMDPs},
 booktitle = {Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'00},
 year = {2000},
 isbn = {1-55860-709-9},
 location = {Stanford, California},
 pages = {406--415},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2073946.2073994},
 acmid = {2073994},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 


% Fitted Q-Iteration in POMDP

@article{DRQ_AAAI_2015,
	author = {Matthew Hausknecht and Peter Stone},
	title = {Deep Recurrent Q-Learning for Partially Observable MDPs},
	conference = {AAAI Fall Symposium Series},
	year = {2015},
	keywords = {Deep Reinforcement Learning; LSTM; Deep Networks; Reinforcement Learning; Atari; Deep Q-Learning},
	abstract = {Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting Deep Recurrent Q-Network (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.},
	url = {https://www.aaai.org/ocs/index.php/FSS/FSS15/paper/view/11673}
}



@article{mnih-dqn-2015,
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and 	Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	Date = {2015/02/26/print},
	Date-Added = {2015-03-03 15:43:42 +0000},
	Date-Modified = {2015-03-03 15:43:42 +0000},
	Day = {26},
	Isbn = {0028-0836},
	Journal = {Nature},
	L3 = {10.1038/nature14236; http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html#supplementary-information},
	M3 = {Letter},
	Month = {02},
	Number = {7540},
	Pages = {529--533},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Title = {Human-level control through deep reinforcement learning},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature14236},
	Volume = {518},
	Year = {2015}
}

@INPROCEEDINGS{neura_fqi_2005,
    author = {Martin Riedmiller},
    title = {Neural fitted Q iteration â first experiences with a data efficient neural reinforcement learning method},
    booktitle = {In 16th European Conference on Machine Learning},
    year = {2005},
    pages = {317--328},
    publisher = {Springer}
}

