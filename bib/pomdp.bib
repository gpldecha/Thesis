% Very early work

@INPROCEEDINGS{ActingUncertainty_1996,
author={A. R. Cassandra and L. P. Kaelbling and J. A. Kurien},
booktitle={Intelligent Robots and Systems '96, IROS 96, Proceedings of the 1996 IEEE/RSJ International Conference on},
title={Acting under uncertainty: discrete Bayesian models for mobile-robot navigation},
year={1996},
volume={2},
pages={963-972 vol.2},
month={Nov}
}

@INPROCEEDINGS{810011,
author={D. Nikovski and I. Nourbakhsh},
booktitle={Computational Intelligence in Robotics and Automation, 1999. CIRA '99. Proceedings. 1999 IEEE International Symposium on},
title={Learning discrete Bayesian models for autonomous agent navigation},
year={1999},
pages={137-143},
keywords={Bayes methods;Markov processes;decision theory;learning (artificial intelligence);mobile robots;navigation;path planning;Baum-Welch algorithm;Markov decision processes;autonomous agent;best-first model;discrete Bayesian models;mobile robots;navigation;path planning;Algorithm design and analysis;Autonomous agents;Bayesian methods;Impedance;Merging;Mobile robots;Navigation;Probability distribution;Robot sensing systems;Strips},
doi={10.1109/CIRA.1999.810011},
month={},}


@ARTICLE{Kaelbling98planningand,
    author = {Leslie Pack Kaelbling and Michael L. Littman and Anthony R. Cassandra},
    title = {Planning and acting in partially observable stochastic domains},
    journal = {ARTIFICIAL INTELLIGENCE},
    year = {1998},
    volume = {101},
    pages = {99--134}
}

% Point Based Value Iteration

@inproceedings{PBVI,
   author = "Joelle Pineau and Geoffrey Gordon and Sebastian Thrun",
   title = "Point-based value iteration: An anytime algorithm for POMDPs",
   booktitle = "International Joint Conference on Artificial Intelligence (IJCAI)",
   pages = "1025 - 1032",
   month = "August",
   year = "2003"
} 

@INPROCEEDINGS{SARSOP,
    author = {Hanna Kurniawati and David Hsu and Wee Sun Lee},
    title = {SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces},
    booktitle = {In Proc. Robotics: Science and Systems},
    year = {2008}
}

@INPROCEEDINGS{POMDP_approach_2010,
AUTHOR = "Y.Z. Du and D. Hsu and H. Kurniawati and W.S. Lee and S.C.W. Ong and S.W. Png",
TITLE = "A POMDP Approach to Robot Motion Planning under Uncertainty",
BOOKTITLE = "Int. Conf. on Automated Planning and Scheduling, Workshop on Solving Real-World POMDP Problems",
URL = "papers/icaps10_pomdpApsInRobotics.pdf",
YEAR = "2010"
}

@ARTICLE{Ross08onlineplanning,
    author = {Stéphane Ross and Joelle Pineau and Sébastien Paquet and Brahim Chaib-draa},
    title = {Online planning algorithms for POMDPs},
    journal = {Journal of Artificial Intelligence Research},
    year = {2008}
}

@ARTICLE{continusou_PBVI,
    author = {Josep M. Porta and Nikos Vlassis and Matthijs T. J. Spaan and Pascal Poupart},
    title = {Point-Based Value Iteration for Continuous POMDPs},
    journal = {JOURNAL OF MACHINE LEARNING RESEARCH},
    year = {2006},
    volume = {7},
    pages = {2329--2367}
}

@article{Perseus_2005,
 author = {Spaan, Matthijs T. J. and Vlassis, Nikos},
 title = {Perseus: Randomized Point-based Value Iteration for POMDPs},
 journal = {J. Artif. Int. Res.},
 issue_date = {July 2005},
 volume = {24},
 number = {1},
 month = aug,
 year = {2005},
 issn = {1076-9757},
 pages = {195--220},
 numpages = {26},
 url = {http://dl.acm.org/citation.cfm?id=1622519.1622525},
 acmid = {1622525},
 publisher = {AI Access Foundation},
 address = {USA},
} 


@article{Macro_uncertainty_2011,
 author = {He, Ruijie and Brunskill, Emma and Roy, Nicholas},
 title = {Efficient Planning Under Uncertainty with Macro-actions},
 journal = {J. Artif. Int. Res.},
 issue_date = {January 2011},
 volume = {40},
 number = {1},
 month = jan,
 year = {2011},
 issn = {1076-9757},
 pages = {523--570},
 numpages = {48},
 url = {http://dl.acm.org/citation.cfm?id=2016945.2016959},
 acmid = {2016959},
 publisher = {AI Access Foundation},
 address = {USA}
} 


@ARTICLE{vf_approx_POMDP_2000,
    author = {Milos Hauskrecht},
    title = {Value-function approximations for partially observable Markov decision processes},
    journal = {Journal of Artificial Intelligence Research},
    year = {2000},
    volume = {13},
    pages = {33--94}
}

@inproceedings{hsu:what,
    author = {Hsu, David and Lee, Wee S. and Rong, Nan},
    booktitle = {NIPS'07},
    citeulike-article-id = {9709602},
    keywords = {pomdp, reinforcement\_learning},
    posted-at = {2011-08-26 10:08:35},
    priority = {2},
    title = {{What makes some POMDP problems easy to approximate?}},
    year = {2007}
}


% Gradient 
%Particle POMDP

@incollection{PF_gradient_pomdp_2008,
    Title = {Particle Filter-based Policy Gradient in POMDPs},
    Url = {http://books.nips.cc/papers/files/nips21/NIPS2008_0628.pdf},
    Booktitle = {Advances in Neural Information Processing Systems 21},
    Author = {Pierre-arnaud Coquelin and Romain Deguest and Rémi Munos},
    Editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
    Year = {2008},
    Pages = {337--344}
} 

@INPROCEEDINGS{Baxter_GPOMDP_2000,
    author = {Jonathan Baxter and Peter L. Bartlett},
    title = {Reinforcement Learning in POMDP's via Direct Gradient Ascent},
    booktitle = {In Proc. 17th International Conf. on Machine Learning},
    year = {2000},
    pages = {41--48},
    publisher = {Morgan Kaufmann}
}



@article{REINFORCE,
year={1992},
issn={0885-6125},
journal={Machine Learning},
volume={8},
number={3-4},
doi={10.1007/BF00992696},
title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
url={http://dx.doi.org/10.1007/BF00992696},
publisher={Kluwer Academic Publishers},
keywords={Reinforcement learning; connectionist networks; gradient descent; mathematical analysis},
author={Williams, RonaldJ.},
pages={229-256},
language={English}
}

@INPROCEEDINGS{Sutton00policygradient,
    author = {Richard S. Sutton and David Mcallester and Satinder Singh and Yishay Mansour},
    title = {Policy gradient methods for reinforcement learning with function approximation},
    booktitle = {In Advances in Neural Information Processing Systems 12},
    year = {2000},
    pages = {1057--1063},
    publisher = {MIT Press}
}


@article{Peters_NN_2008,
  author =		 "Peters, J. and  Schaal, S.",
  year =		 "2008",
  title =		 "Reinforcement learning of motor skills with policy gradients",
  booktitle =		 "Neural Networks",
  key =			 "reinforcement learning, policy gradient methods, natural gradients, natural actor-critic, motor skills, motor primitives",
  URL =			 "http://www-clmc.usc.edu/publications/P/peters-NN2008.pdf",
  number =		 "4",
  pages =		 "682-97",
  ISBN/ISSN =		 "0893-6080 (Print)",
  crossref =		 "p10271"
}

% Next best touch

@INPROCEEDINGS{next_best_touch,
author={Hebert, P. and Howard, T. and Hudson, N. and Ma, J. and Burdick, J.W.},
booktitle={Robotics and Automation (ICRA), 2013 IEEE International Conference on},
title={The next best touch for model-based localization},
year={2013},
month={May},
pages={99-106},
keywords={dexterous manipulators;image sensors;mobile robots;parameter estimation;pose estimation;robot vision;touch (physiological);ARM-S;DARPA autonomous robotic manipulation software robot;autonomous robot;contact method;information gain metric;model class estimation;model parameter estimation;model-based localization;next best touch;next sensing action;object localization;object pose uncertainty;tactile method;Computational modeling;Entropy;Equations;Gain measurement;Mathematical model;Robots;Trajectory},
doi={10.1109/ICRA.2013.6630562},
ISSN={1050-4729}
}

% Probabilistic Robotics (BOOK)

@book{Thrun_2005,
 author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
 title = {Probabilistic Robotics (Intelligent Robotics and Autonomous Agents)},
 year = {2005},
 isbn = {0262201623},
 publisher = {The MIT Press},
} 


% 		Optimal control methods

@INPROCEEDINGS{Platt-RSS-10,
    AUTHOR    = {R. Platt AND R. Tedrake AND L. Kaelbling AND T. Lozano-Perez},
    TITLE     = {Belief space planning assuming maximum likelihood observations},
    BOOKTITLE = {Proceedings of Robotics: Science and Systems},
    YEAR      = {2010},
    ADDRESS   = {Zaragoza, Spain},
    MONTH     = {June}
}


 
%		Belief space planning (no control)

@INPROCEEDINGS{Quadrator_2008,
author={Ruijie He and Prentice, S. and Roy, N.},
booktitle={Robotics and Automation, 2008. ICRA 2008. IEEE International Conference on},
title={Planning in information space for a quadrotor helicopter in a GPS-denied environment},
year={2008},
month={May},
pages={1814-1820},
keywords={Kalman filters;helicopters;path planning;GPS-denied environment;belief roadmap algorithm;global positioning;information space;localization degree;motion planning;probabilistic roadmap algorithm;quadrotor helicopter;unscented Kalman filter;Global Positioning System;Helicopters;Helium;Intelligent sensors;Land vehicles;Motion planning;Remotely operated vehicles;Space vehicles;Trajectory;Unmanned aerial vehicles},
doi={10.1109/ROBOT.2008.4543471},
ISSN={1050-4729}
}

@Article{BelRoadMap_2009,
  author = 	 {S. Prentice and N. Roy},
  title = 	 {The Belief Roadmap: Efficient Planning in Belief Space by Factoring the Covariance},
  journal = 	 {International Journal of Robotics Research},
  year = 	 {2009},
  volume =	 {8},
  number =	 {11-12},
  pages =	 {1448-1465},
  month =	 {December}
}
  



% Active Policy search

@article{Bayesian_explor_exploit_2009,
year={2009},
issn={0929-5593},
journal={Autonomous Robots},
volume={27},
number={2},
doi={10.1007/s10514-009-9130-2},
title={A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot},
url={http://dx.doi.org/10.1007/s10514-009-9130-2},
publisher={Springer US},
keywords={Bayesian optimization; Online path planning; Sequential experimental design; Attention and gaze planning; Active vision; Dynamic sensor networks; Active learning; Policy search; Active SLAM; Model predictive control; Reinforcement learning},
author={Martinez-Cantin, Ruben and de Freitas, Nando and Brochu, Eric and Castellanos, José and Doucet, Arnaud},
pages={93-103},
language={English}
}


% Policy search

@inproceedings{Sol_POMDP_Policy_space_1998,
 author = {Hansen, Eric A.},
 title = {Solving POMDPs by Searching in Policy Space},
 booktitle = {Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'98},
 year = {1998},
 isbn = {1-55860-555-X},
 location = {Madison, Wisconsin},
 pages = {211--219},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2074094.2074119},
 acmid = {2074119},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Pegasus_2000,
 author = {Ng, Andrew Y. and Jordan, Michael},
 title = {PEGASUS: A Policy Search Method for Large MDPs and POMDPs},
 booktitle = {Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'00},
 year = {2000},
 isbn = {1-55860-709-9},
 location = {Stanford, California},
 pages = {406--415},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2073946.2073994},
 acmid = {2073994},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 


@INPROCEEDINGS{MCVI,
    author = {Haoyu Bai and David Hsu and Wee Sun Lee and Vien A. Ngo},
    title = {Monte Carlo Value Iteration for Continuous-State POMDPs},
    booktitle = {WORKSHOP ON THE ALGORITHMIC FOUNDATIONS OF ROBOTICS},
    year = {2010},
    publisher = {}
}


% Sample based POMDP policy

@inproceedings{Rand_belief_space_replanning,
  added-at = {2011-09-11T00:00:00.000+0200},
  author = {Hauser, Kris},
  booktitle = {WAFR},
  crossref = {conf/wafr/2010},
  editor = {Hsu, David and Isler, Volkan and Latombe, Jean-Claude and Lin, Ming C.},
  ee = {http://dx.doi.org/10.1007/978-3-642-17452-0_12},
  isbn = {978-3-642-17451-3},
  pages = {193-209},
  publisher = {Springer},
  series = {Springer Tracts in Advanced Robotics},
  title = {Randomized Belief-Space Replanning in Partially-Observable Continuous Spaces.},
  volume = 68,
  year = 2010
}


% Pursuit evasion in a multi robot domain

@INPROCEEDINGS{Pursuit_evasion_2004,
    author = {Brian P. Gerkey and Sebastian Thrun and Geoff Gordon},
    title = {Visibility-based pursuit-evasion with limited field of view},
    booktitle = {International Journal of Robotics Research},
    year = {2004},
    pages = {20--27}
}



% Reward functions

@INPROCEEDINGS{Mihaylova02activesensing,
    author = {L. Mihaylova and T. Lefebvre and H. Bruyninckx and K. Gadeyne and J. De Schutter},
    title = {Active Sensing for Robotics - A Survey},
    booktitle = {in Proc. 5 th Int’l Conf. On Numerical Methods and Applications},
    year = {2002},
    pages = {316--324}
}


% deChambrierBillard2014

@article{deChambrierBillard2014,
year={2014},
journal={Robotics and Biomimetics},
volume={1},
number={1},
title={Learning search polices from humans in a partially observable context},
publisher={Springer Berlin Heidelberg},
author={Chambrier, Guillaumede and Billard, Aude}
}

@proceedings{PbD_Sylvain_static_representation,
    author = {Calinon, S. and Guenter, F. and Billard, A.},
    citeulike-article-id = {1222185},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/robot.2006.1642154},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1642154},
    doi = {10.1109/robot.2006.1642154},
    journal = {Robotics and Automation, 2006. ICRA 2006. Proceedings 2006 IEEE International Conference on},
    keywords = {algorithms, learning-by-demo},
    pages = {2978--2983},
    posted-at = {2009-03-27 15:55:39},
    priority = {5},
    title = {{On learning the statistical representation of a task and generalizing it to various contexts}},
    url = {http://dx.doi.org/10.1109/robot.2006.1642154},
    year = {2006}
}


% function approximation 


@INPROCEEDINGS{Gordon95stablefunction,
    author = {Geoffrey J. Gordon},
    title = {Stable Function Approximation in Dynamic Programming},
    booktitle = {IN MACHINE LEARNING: PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE},
    year = {1995},
    publisher = {Morgan Kaufmann}
}

@book{VonNeumann1944,
    author = "Von Neumann, John and Morgenstern, O.",
    title = "The theory of games and economic behavior",
    year = "1990",
    publisher = "Princeton",
    edition = "3"
}

@article{Bernoulli1954,
  author = {Bernoulli, D.},
  journal = {Econometrica},
  number = {1},
  pages = {23--36},
  title = {{Exposition of a New Theory on the Measurement of Risk (1748)}},
  volume = {22},
  year = {1954}
}

@TechReport{Ellsberg_paradox,
  author={Daniel Ellsberg},
  title={{Risk, Ambiguity and the Savage Axioms}},
  year=2000,
  month=Dec,
  institution={David K. Levine},
  type={Levine's Working Paper Archive},
  url={http://ideas.repec.org/p/cla/levarc/7605.html},
  number={7605},
  abstract={No abstract is available for this item.},
  keywords={},
}


@article{MACHINA01051987,
author = {MACHINA, MARK J.}, 
title = {Decision-Making in the Presence of Risk},
volume = {236}, 
number = {4801}, 
pages = {537-543}, 
year = {1987}, 
doi = {10.1126/science.236.4801.537}, 
abstract ={Proposed in the 18th century by Cramer and Bernoulli and formally axiomatized in the 20th century by von Neumann and Morgenstern and others, the expected utility model has long been the dominant framework for the analysis of decision-making under risk. A growing body of experimental evidence, however, indicates that individuals systematically violate the key behavioral assumption of this model, the so-called independence axiom. This has led to the development and analysis of nonexpected utility models of decision-making. Although recent work in this area has shown that the analytical results of expected utility theory are more robust than previously supposed, other important issues remain unresolved.}, 
URL = {http://www.sciencemag.org/content/236/4801/537.abstract}, 
eprint = {http://www.sciencemag.org/content/236/4801/537.full.pdf}, 
journal = {Science} 
}

@incollection{Billard08chapter,
author="A. Billard and S. Calinon and R. Dillmann and S. Schaal",
title="Robot Programming by Demonstration",
booktitle="Handbook of Robotics",
editor="B. Siciliano and O. Khatib",
publisher="Springer",
address="Secaucus, NJ, USA",
year="2008",
pages="1371--1394"
}

@inproceedings{rai2013learning,
  title={Learning from failed demonstrations in unreliable systems},
  author={Rai, Akshara and De Chambrier, Guillaume and Billard, Aude},
  booktitle={Humanoid Robots (Humanoids), 2013 13th IEEE-RAS International Conference on},
  pages={410--416},
  year={2013},
  organization={IEEE}
}



