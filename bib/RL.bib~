%% Book


% Sutton

@Book{sutton98a,
  	author	=	 {Richard S. Sutton and Andrew G. Barto},
  	title	=	 {Reinforcement Learning: An Introduction},
  	publisher =	 {{MIT} Press},
  	year	=	 1998,
  	url	= 	 {http://www.cs.ualberta.ca/\%7Esutton/book/ebook/the-book.html}
}


@article{Tree_batch_2005,
 	author = {Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
 	title = {Tree-Based Batch Mode Reinforcement Learning},
 	journal = {J. Mach. Learn. Res.},
 	volume = {6},
 	month = dec,
 	year = {2005},
 	pages = {503--556}
 } 

@incollection{heli_2004,
	title = {Autonomous Helicopter Flight via Reinforcement Learning},
	author = {H. J. Kim and Michael I. Jordan and Shankar Sastry and Andrew Y. Ng},
	booktitle = {Advances in Neural Information Processing Systems 16},
	editor = {S. Thrun and L. K. Saul and B. Sch\"{o}lkopf},
	pages = {799--806},
	year = {2004},
	publisher = {MIT Press},
	url = {http://papers.nips.cc/paper/2455-autonomous-helicopter-flight-via-reinforcement-learning.pdf}
}

@article{RL_robots_surv_2013,
   	author = "J. Kober and J. Andrew (Drew) Bagnell and J. Peters",
   	title = "Reinforcement Learning in Robotics: A Survey",
   	journal = "International Journal of Robotics Research",
   	month = "July",
   	year = "2013",
} 

% Important concepts

@INPROCEEDINGS{Safe_val_function_1995,
	author = {Justin A. Boyan and Andrew W. Moore},
    	title = {Generalization in Reinforcement Learning: Safely Approximating the Value Function},
    	booktitle = {Advances in Neural Information Processing Systems 7},
    	year = {1995},
    	pages = {369--376},
    	publisher = {MIT Press}
}

@INPROCEEDINGS{Sutton00policygradient,
    author = {Richard S. Sutton and David Mcallester and Satinder Singh and Yishay Mansour},
    title = {Policy gradient methods for reinforcement learning with function approximation},
    booktitle = {In Advances in Neural Information Processing Systems 12},
    year = {2000},
    pages = {1057--1063},
    publisher = {MIT Press}
}


% Gradient policy search

﻿@Article{reinforce_1992,
	author="Williams, Ronald J.",
	title="Simple statistical gradient-following algorithms for connectionist reinforcement learning",
	journal="Machine Learning",
	volume="8",
	number="3",
	pages="229--256",
	year="1992",
	doi="10.1007/BF00992696",
	url="http://dx.doi.org/10.1007/BF00992696"
}

@INPROCEEDINGS{gpomdp_2000,
    author = {Jonathan Baxter and Peter L. Bartlett},
    title = {Reinforcement Learning in POMDP's via Direct Gradient Ascent},
    booktitle = {In Proc. 17th International Conf. on Machine Learning},
    year = {2000},
    pages = {41--48},
    publisher = {Morgan Kaufmann}
}

@INPROCEEDINGS{eNAC_2003,
    author = {Sethu Vijayakumar and Tomohiro Shibata and Stefan Schaal},
    title = {Reinforcement learning for humanoid robotics},
    booktitle = {Autonomous Robot},
    year = {2003},
    pages = {2002}
}

@inproceedings{pancake_2010,
  address = {Taipei, Taiwan},
  author = {Kormushev, P. and Calinon, S. and Caldwell, D. G.},
  booktitle = {Proc. {IEEE/RSJ} Intl Conf. on Intelligent Robots and Systems ({IROS})},
  month = {October},
  pages = {3232--3237},
  title = {Robot Motor Skill Coordination with {EM}-based Reinforcement Learning},
  year = 2010
}

﻿@Article{Wang2016,
	author="Wang, Jiexin and Uchibe, Eiji and Doya, Kenji",
	title="EM-based policy hyper parameter exploration: application to standing and balancing of a two-wheeled smartphone robot",
	journal="Artificial Life and Robotics",
	year="2016",
	volume="21",
	number="1",
	pages="125--131",
	doi="10.1007/s10015-015-0260-7",
	url="http://dx.doi.org/10.1007/s10015-015-0260-7"
}

@INPROCEEDINGS{PoWER_2009,
	author={J. Kober and J. Peters},
	booktitle={Robotics and Automation, 2009. ICRA '09. IEEE International Conference on},
	title={Learning motor primitives for robotics},
	year={2009},
	pages={2112-2118},
	doi={10.1109/ROBOT.2009.5152577},
	month={May}
}

@INPROCEEDINGS{archery_2010,
	author={P. Kormushev and S. Calinon and R. Saegusa and G. Metta},
	booktitle={Humanoid Robots (Humanoids), 2010 10th IEEE-RAS International Conference on},
	title={Learning the skill of archery by a humanoid robot iCub},
	year={2010},
	pages={417-423},
	doi={10.1109/ICHR.2010.5686841},
	month={Dec}
}

@article{NAC_2008,
	title = "Natural Actor-Critic ",
	journal = "15th European Symposium on Artificial Neural Networks ",
	volume = "71",
	number = "7-9",
	pages = "1180-1190",
	year = "2008",
	doi = "http://dx.doi.org/10.1016/j.neucom.2007.11.026",
	url = "http://www.sciencedirect.com/science/article/pii/S0925231208000532",
	author = "Jan Peters and Stefan Schaal",
}


@INPROCEEDINGS{dmp_iros_2011,
	author={F. Stulp and E. Theodorou and M. Kalakrishnan and P. Pastor and L. Righetti and S. Schaal},
	booktitle={Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on},
	title={Learning motion primitive goals for robust manipulation},
	year={2011},
	pages={325-331},
	keywords={Cost function;Grasping;Learning;Robots;Shape;Trajectory;Uncertainty},
	doi={10.1109/IROS.2011.6094877},
	month={Sept}
}

@INPROCEEDINGS{sigma_hull_iros_2013,
	author={A. Lee and Y. Duan and S. Patil and J. Schulman and Z. McCarthy and J. van den Berg and K. Goldberg and P. Abbeel},
	booktitle={Intelligent Robots and Systems (IROS), 2013 IEEE/RSJ International Conference on},
	title={Sigma hulls for Gaussian belief space planning for imprecise articulated robots amid obstacles},
	year={2013},
	pages={5660-5667},
	doi={10.1109/IROS.2013.6697176},
	month={Nov}
}

% Survey

@article{p_search_surv_2011,
	author 	= {Marc Peter Deisenroth and Gerhard Neumann and Jan Peters},
	year 	= {2011},
	volume  = {2},
	journal = {Foundations and Trends in Robotics},
	title   = {A Survey on Policy Search for Robotics},
	number  = {1-2},
	pages   = {1-142},
	doi 	= {10.1561/2300000021},
	url 	= {http://dx.doi.org/10.1561/2300000021}
}

% Fitted Reinforcement Learning

@inproceedings{fqi_nips_peter_2009,
  	title = {Fitted Q-iteration by Advantage Weighted Regression},
  	author = {Neumann, G. and Peters, J.},
  	journal = {Advances in neural information processing systems 21 : 22nd Annual Conference on Neural Information Processing Systems 2008},
  	booktitle = {Advances in neural information processing systems 21},
  	pages = {1177-1184},
  	month = jun,
  	year = {2009}
}

@article{batch_synth_traj_2013,
  author    = {Raphael Fonteneau and Susan A. Murphy and Louis Wehenkel and Damien Ernst},
  title     = {Batch mode reinforcement learning based on the synthesis of artificial trajectories},
  journal   = {Annals Oper Res},
  volume    = {208},
  number    = {1},
  pages     = {383--416},
  year      = {2013},
  url       = {http://dx.doi.org/10.1007/s10479-012-1248-5},
  doi       = {10.1007/s10479-012-1248-5},
}


@Inbook{fnac_ca_2008,
	author="Melo, Francisco S. and Lopes, Manuel",
	title="Fitted Natural Actor-Critic: A New Algorithm for Continuous State-Action MDPs",
	bookTitle="Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2008, Antwerp, Belgium, September 15-19, 2008, Proceedings, Part II",
	year="2008",
	pages="66--81",
	doi="10.1007/978-3-540-87481-2_5",
	url="http://dx.doi.org/10.1007/978-3-540-87481-2_5"
}

@Inbook{Riedmiller2005,
	author="Riedmiller, Martin",
	title="Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method",
	bookTitle="Machine Learning: ECML 2005: 16th European Conference on Machine Learning, Porto, Portugal, October 3-7, 2005. Proceedings",
	year="2005",
	pages="317--328",
	doi="10.1007/11564096_32",
	url="http://dx.doi.org/10.1007/11564096_32"
}


@Article{EGW05,
  	author       = "Ernst, Damien and Geurts, Pierre and Wehenkel, Louis",
  	title        = "Tree-Based Batch Mode Reinforcement Learning",
  	journal      = "Journal of Machine Learning Research",
  	volume       = "6",
  	pages        = "503-556",
  	month        = "April",
  	year         = "2005",
 }

@INPROCEEDINGS{rl_gmm_2010,
	author={A. Agostini and E. Celaya},
	booktitle={The 2010 International Joint Conference on Neural Networks (IJCNN)},
	title={Reinforcement Learning with a Gaussian mixture model},
	year={2010},
	pages={1-8},
	doi={10.1109/IJCNN.2010.5596306},
	month={July}
}

@INPROCEEDINGS{fvi_uav_2010,
	author={H. Bou-Ammar and H. Voos and W. Ertel},
	booktitle={2010 IEEE International Conference on Control Applications},
	title={Controller design for quadrotor UAVs using reinforcement learning},
	year={2010},
	pages={2130-2135},
	month={Sept},
	doi={10.1109/CCA.2010.5611206},
}


@ARTICLE{rl_ac_surv_2012,
	author={I. Grondman and L. Busoniu and G. A. D. Lopes and R. Babuska},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	title={A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients},
	year={2012},
	volume={42},
	number={6},
	pages={1291-1307},
	doi={10.1109/TSMCC.2012.2218595},
	month={Nov}
}

@ARTICLE{kernel_rl_ormoneit_2002,
	author={D. Ormoneit and P. Glynn},
	journal={IEEE Transactions on Automatic Control},
	title={Kernel-based reinforcement learning in average-cost problems},
	year={2002},
	volume={47},
	number={10},
	pages={1624-1636},
	doi={10.1109/TAC.2002.803530},
	month={Oct}
}

@article{kernel_BarretoPP14,
	author    = {Andr{\'{e}} da Motta Salles Barreto and Doina Precup and Joelle Pineau},
  	title     = {Practical Kernel-Based Reinforcement Learning},
  	journal   = {CoRR},
  	volume    = {abs/1407.5358},
  	year      = {2014},
  	url       = {http://arxiv.org/abs/1407.5358},
 }

@InProceedings{stable_FA_gordon_1995,
 	author 	  = {Gordon, Geoffrey J.},
  	booktitle = {Proceedings of the Twelfth International Conference on Machine Learning (ICML)},
 	title 	  = {Stable Function Approximation in Dynamic Programming},
 	year 	  = {1995},
 	publisher = {Carnegie Mellon University},
  	url 	  = {"http://www.cs.cmu.edu/~ggordon/ml95-stable-dp.ps.gz"}
} 


@CONFERENCE{ACML_variance_2015,
  	author 	    = {Zhao, T. and Niu, G. and Xie, N. and Yang, J. and Sugiyama, M.},
  	title       = {Regularized Policy Gradients: {D}irect Variance Reduction in Policy Gradient Estimation},
  	booktitle   = {Proceedings of the Fourth Asian Conference on Machine Learning (ACML2015)},
  	year        = {2015},
  	series      = {JMLR Workshop and Conference Proceedings},
  	month       = {Nov},
  	volume      = {45},
 	pages       = {333--348}
}




%% DEEP LEARNING

@INPROCEEDINGS{Lange_riedmiller_2010,
	author 		={S. Lange and M. Riedmiller},
	booktitle 	={The 2010 International Joint Conference on Neural Networks (IJCNN)},
	title 		={Deep auto-encoder neural networks in reinforcement learning},
	year 		={2010},
	pages	 	={1-8},
	month	 	={July}
}

%% BOOK

@book{RL_book_2010,
  	author  	= {Szepesv\'ari, Csaba},
  	booktitle  	= {Algorithms for Reinforcement Learning},
  	publisher  	= {Morgan and Claypool Publishers},
  	series  	= {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  	title  		= {Algorithms for Reinforcement Learning},
  	url  		= {http://dx.doi.org/10.2200/S00268ED1V01Y201005AIM009},
  	year 	 	= 2010
}

@book{RL_state_art_2012,
  	author	 	= {Wiering, Marco and van Otterio, Martijn},
  	booktitle 	= {Reinforcement Learning State-of-the-Art},
  	publisher 	= {Springer-Verlag Berlin Heidelberg},
  	title 		= {Reinforcement Learning State-of-the-Art},
  	year 		= {2012}
}


@MISC{matrix_ckb,
    author       = "K. B. Petersen and M. S. Pedersen",
    title        = "The Matrix Cookbook",
    year         = "2012",
    month        = "nov",
    keywords     = "Matrix identity, matrix relations, inverse, matrix derivative",
    publisher    = "Technical University of Denmark",
    address      = "",
    note         = "Version 20121115",
    url          = "http://www2.imm.dtu.dk/pubdb/p.php?3274",
    abstract     = "Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices."
}
 
@book{Bishop_2006,
 	author = {Bishop, Christopher M.},
 	title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 	year = {2006},
 	isbn = {0387310738},
 	publisher = {Springer-Verlag New York, Inc.},
 	address = {Secaucus, NJ, USA},
} 



